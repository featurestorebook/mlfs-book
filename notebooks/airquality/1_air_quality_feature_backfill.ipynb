{
 "cells": [
  {
   "cell_type": "code",
   "id": "f3fe026a20d9a048",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T12:02:31.915424Z",
     "start_time": "2025-11-14T12:02:31.895980Z"
    }
   },
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", module=\"IPython\")\n",
    "\n",
    "def is_google_colab() -> bool:\n",
    "    if \"google.colab\" in str(get_ipython()):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def clone_repository() -> None:\n",
    "    !git clone https://github.com/featurestorebook/mlfs-book.git\n",
    "    %cd mlfs-book\n",
    "\n",
    "def install_dependencies() -> None:\n",
    "    !pip install --upgrade uv\n",
    "    !uv pip install --all-extras --system --requirement pyproject.toml\n",
    "\n",
    "if is_google_colab():\n",
    "    clone_repository()\n",
    "    install_dependencies()\n",
    "    root_dir = str(Path().absolute())\n",
    "    print(\"Google Colab environment\")\n",
    "else:\n",
    "    root_dir = Path().absolute()\n",
    "    # Strip ~/notebooks/ccfraud from PYTHON_PATH if notebook started in one of these subdirectories\n",
    "    if root_dir.parts[-1:] == ('airquality',):\n",
    "        root_dir = Path(*root_dir.parts[:-1])\n",
    "    if root_dir.parts[-1:] == ('notebooks',):\n",
    "        root_dir = Path(*root_dir.parts[:-1])\n",
    "    root_dir = str(root_dir) \n",
    "    print(\"Local environment\")\n",
    "\n",
    "print(f\"Root dir: {root_dir}\")\n",
    "\n",
    "# Add the root directory to the `PYTHONPATH` \n",
    "if root_dir not in sys.path:\n",
    "    sys.path.append(root_dir)\n",
    "    print(f\"Added the following directory to the PYTHONPATH: {root_dir}\")\n",
    "\n",
    "# Set the environment variables from the file <root_dir>/.env\n",
    "from mlfs import config\n",
    "settings = config.HopsworksSettings(_env_file=f\"{root_dir}/.env\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local environment\n",
      "Root dir: /home/simon/PycharmProjects/mlfs-book_scalabel_ml\n",
      "HopsworksSettings initialized!\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "id": "40ba06b651366fb",
   "metadata": {},
   "source": [
    "<span style=\"font-width:bold; font-size: 3rem; color:#333;\">- Part 01: Feature Backfill for Air Quality Data</span>\n",
    "\n",
    "\n",
    "## üóíÔ∏è You have the following tasks\n",
    "1. Choose an Air Quality Sensor\n",
    "2. Update the country, city, and street information to point to YOUR chosen Air Quality Sensor\n",
    "3. Download historical measures for your Air Quality Sensor as a CSV file\n",
    "4. Update the path of the CSV file in this notebook to point to the one that you downloaded\n",
    "5. Create an account on www.hopsworks.ai and get your HOPSWORKS_API_KEY\n",
    "6. Run this notebook\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dabf5dc8bcff80e",
   "metadata": {},
   "source": [
    "### <span style='color:#ff5f27'> üìù Imports"
   ]
  },
  {
   "cell_type": "code",
   "id": "302b80713a05d82e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T12:02:31.973896Z",
     "start_time": "2025-11-14T12:02:31.968272Z"
    }
   },
   "source": [
    "# imports\n",
    "import datetime\n",
    "import requests\n",
    "import pandas as pd\n",
    "import hopsworks\n",
    "from mlfs.airquality import util\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "id": "7e68baf331c87428",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üåç STEP 1: Pick your Air Quality Sensor</span>\n",
    "\n",
    "![image.png](attachment:b40d25b6-4994-4674-970b-a1eb4a14b9ad.png)\n",
    "\n",
    "  * Find your favorite sensor on https://waqi.info/ \n",
    "  * The sensor should have a URL in one of the two following forms: \n",
    "\n",
    "  `https://aqicn.org/station/<CITY OR COUNTRY NAME>/<STREET>`\n",
    "  or\n",
    "\n",
    "  `https://aqicn.org/station/@36655//`\n",
    "  or \n",
    "  \n",
    "  `https://aqicn.org/city/<CITY OR COUNTRY NAME>/<STREET>`\n",
    "\n",
    "With your URL, we will need to do two things:\n",
    "\n",
    " * download the historical air quality readings as a CSV file\n",
    " * note down the URL for the real-time API (you will need to create an API key for accessing this).\n",
    "\n",
    "If your sensor's URL has one of the first two formats (the first URL path component is `station`), you will find the links to both historical CSV data and the real-time API on the same web page.\n",
    "\n",
    "However, if your sensor's URL has the last format above (the first URL path component is `city` instead of `station`), then you will need to use 2 different URLs - one to download the historical CSV data and one for the real-time air quality measurements. You will find both of those links in the \"Air quality historical data\" section. Click on the \"Historical air quality data\" when you need to download the CSV file, and when you need the real-time API, click on the \"Real-time air quality data\".\n",
    "\n",
    "Some examples of URLs for stations:\n",
    "\n",
    " * https://aqicn.org/station/sweden/stockholm-hornsgatan-108-gata/ - in Stockholm, Sweden\n",
    " * https://aqicn.org/station/@36655// - in Hell's Kitchen, Manhatten, New York, USA\n",
    " * https://aqicn.org/station/nigeria-benin-city-edo-state-secretariat-palm-house/ - in Benin City, Nigeria\n",
    " * https://aqicn.org/station/india/mumbai/sion/ - Sion in Mumbai, India\n",
    "\n",
    "Here is what the webpage at URL for the Stockholm sensor looks like:\n",
    "\n",
    "![station.png](attachment:1922302e-13b9-469d-ba75-63dabf7b4475.png)\n",
    "\n",
    "__When you pick a sensor for your project, there are 2 things the sensor MUST have__:\n",
    "  1. __PM 2.5__ measurements\n",
    "  2. __Good Historical Values__ for download as a CSV file\n",
    "\n",
    "__Write down the country, city, and the street for your sensor.__\n",
    "\n",
    "We will use the city name to download weather data for your sensor, and we will store the country and street values in the sensor's feature group."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35412d12941f51ce",
   "metadata": {},
   "source": [
    "## What makes a good quality Air Quality Sensor?\n",
    "\n",
    "In the image below, we can see below that our sensor in Stockholm fulfills our 2 requirements. It has:\n",
    "  1. __PM 2.5__ measurements (see upper red-ringed value in image below)\n",
    "  2. __Good Historical Measurements__ with few missing values (see lower red-ringed values in image below) \n",
    "\n",
    "![sensor.png](attachment:46ebde65-85ff-4b12-a560-65230881db0b.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403fc7c2369a618f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcefa12db5266951",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üåç STEP 2: Download the Historical Air Quality </span>\n",
    "\n",
    "You can download a CSV file containing the historical air quality data from your your sensor's URL.\n",
    "Scroll down to the section \"Air Quality Historical Data\". Click on the PM2.5 option and save the file to the `data` directory in your forked version of this Github repository. Note the name of your CSV file, you will need \n",
    "\n",
    "\n",
    "![download-csv.png](attachment:ab17240a-17ad-47de-97af-2a3a1d32f247.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf76d8f4196bebf",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üåç STEP 3: Get an AQICN API Token and Store it in .env file</span>\n",
    "\n",
    "You have to first get your AQI API key [from here](https://aqicn.org/data-platform/token/):\n",
    "\n",
    "![image.png](attachment:9336a7d3-f7dc-4aec-a854-78e787e4493e.png)\n",
    "\n",
    "\n",
    "Save the API KEY to ~/.env file in the root directory of your project\n",
    "\n",
    " * mv .env.example .env\n",
    " * edit .env\n",
    "\n",
    "In the .env file, update AQICN_API_KEY:\n",
    "\n",
    "`AQICN_API_KEY=\"put API KEY value in this string\"`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d525f55c2abe3061",
   "metadata": {},
   "source": [
    "## Hopsworks API Key\n",
    "You need to have registered an account on app.hopsworks.ai.\n",
    "\n",
    "Save the HOPSWORKS_API_KEY  to ~/.env file in the root directory of your project\n",
    "\n",
    " * mv .env.example .env\n",
    " * edit .env\n",
    "\n",
    "In the .env file, update HOPSWORKS_API_KEY:\n",
    "\n",
    "`HOPSWORKS_API_KEY=\"put API KEY value in this string\"`\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "815e854415ee4d29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T12:02:35.399560Z",
     "start_time": "2025-11-14T12:02:32.030271Z"
    }
   },
   "source": [
    "project = hopsworks.login()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-14 13:02:32,031 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-11-14 13:02:32,035 INFO: Initializing external client\n",
      "2025-11-14 13:02:32,036 INFO: Base URL: https://c.app.hopsworks.ai:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-14 13:02:34,001 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1279143\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "id": "39875bccae9c8c96",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üåç STEP 4: Get the AQICN_URL and API key. Enter country, city, street names for your Sensor.</span>\n",
    "\n",
    "You can find your __AQICN_URL__ if you scroll down the webpage for your sensor - it is the URL inside the redbox here.\n",
    "You shouldn't include the last part of the url - \"/?token=\\__YOUR_TOKEN\\__\". \n",
    "It is bad practice to save TOKENs (aka API KEYs) in your source code - you might make it public if you check that code into Github!\n",
    "We will fill in the token later by saving the AQICN_API_KEY as a secret in Hopsworks.\n",
    "\n",
    "![stockholm-rt-api.png](attachment:70fea299-d303-49f8-99ba-43e981d7c3aa.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "3ee7cf72271e417",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T12:02:36.624836Z",
     "start_time": "2025-11-14T12:02:35.464314Z"
    }
   },
   "source": [
    "today = datetime.date.today()\n",
    "\n",
    "#csv_file=f\"{root_dir}/data/air-quality-data.csv\"\n",
    "csv_file=f\"{root_dir}/data/stockholm-hornsgatan 108 gata-air-quality.csv\"\n",
    "\n",
    "util.check_file_path(csv_file)\n",
    "\n",
    "# taken from ~/.env. You can also replace settings.AQICN_API_KEY with the api key value as a string \"....\"\n",
    "if settings.AQICN_API_KEY is None:\n",
    "    print(\"You need to set AQICN_API_KEY either in this cell or in ~/.env\")\n",
    "    sys.exit(1)\n",
    "\n",
    "AQICN_API_KEY = settings.AQICN_API_KEY.get_secret_value() \n",
    "aqicn_url = \"https://api.waqi.info/feed/@10009\"\n",
    "country = \"Sweden\"\n",
    "city = \"Stockholm\"\n",
    "street = \"Hornsgatan-108\"\n",
    "# If this API call fails (it fails in a github action), then set longitude and latitude explicitly - comment out next line\n",
    "latitude, longitude = util.get_city_coordinates(city)\n",
    "# Uncomment this if API call to get longitude and latitude\n",
    "#latitude = \"59.314017450051836\"\n",
    "#longitude = \"18.075630285191593\"\n",
    "\n",
    "\n",
    "print(f\"Found AQICN_API_KEY: {AQICN_API_KEY}\")\n",
    "\n",
    "secrets = hopsworks.get_secrets_api()\n",
    "# Replace any existing secret with the new value\n",
    "secret = secrets.get_secret(\"AQICN_API_KEY\")\n",
    "if secret is not None:\n",
    "    secret.delete()\n",
    "    print(\"Replacing existing AQICN_API_KEY\")\n",
    "\n",
    "secrets.create_secret(\"AQICN_API_KEY\", AQICN_API_KEY)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File successfully found at the path: /home/simon/PycharmProjects/mlfs-book_scalabel_ml/data/stockholm-hornsgatan 108 gata-air-quality.csv\n",
      "Found AQICN_API_KEY: 82374bd41d9f7773a15f8dbcf600c04f2be4d90f\n",
      "Replacing existing AQICN_API_KEY\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Secret('AQICN_API_KEY', 'PRIVATE')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "id": "886c888af5f16c87",
   "metadata": {},
   "source": [
    "### Validate that the AQICN_API_KEY you added earlier works\n",
    "\n",
    "The cell below should print out something like:\n",
    "\n",
    "![image.png](attachment:832cc3e9-876c-450f-99d3-cc97abb55b13.png)"
   ]
  },
  {
   "cell_type": "code",
   "id": "f5b0734fc8fa525c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T12:02:38.479048Z",
     "start_time": "2025-11-14T12:02:36.698162Z"
    }
   },
   "source": [
    "try:\n",
    "    aq_today_df = util.get_pm25(aqicn_url, country, city, street, today, AQICN_API_KEY)\n",
    "except hopsworks.RestAPIError:\n",
    "    print(\"It looks like the AQICN_API_KEY doesn't work for your sensor. Is the API key correct? Is the sensor URL correct?\")\n",
    "\n",
    "aq_today_df.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   pm25 country       city          street       date  \\\n",
       "0   7.0  Sweden  Stockholm  Hornsgatan-108 2025-11-14   \n",
       "\n",
       "                                 url  \n",
       "0  https://api.waqi.info/feed/@10009  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pm25</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>street</th>\n",
       "      <th>date</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>Hornsgatan-108</td>\n",
       "      <td>2025-11-14</td>\n",
       "      <td>https://api.waqi.info/feed/@10009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "id": "f1d16e0ae2d1b979",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üåç STEP 5: Read your CSV file into a DataFrame </span>\n",
    "\n",
    "The cell below will read up historical air quality data as a CSV file into a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "id": "7b3f0c93c23cfd59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T12:02:38.757648Z",
     "start_time": "2025-11-14T12:02:38.741278Z"
    }
   },
   "source": [
    "df = pd.read_csv(csv_file,  parse_dates=['date'], skipinitialspace=True)\n",
    "df"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "           date  pm25  pm10   no2\n",
       "0    2025-11-01   9.0   8.0   7.0\n",
       "1    2025-11-02  22.0   6.0  12.0\n",
       "2    2025-11-03  14.0   4.0   6.0\n",
       "3    2025-11-04  10.0   6.0   8.0\n",
       "4    2025-11-05  15.0   9.0  11.0\n",
       "...         ...   ...   ...   ...\n",
       "2909 2017-10-24   NaN   NaN   5.0\n",
       "2910 2017-10-25   NaN   NaN  10.0\n",
       "2911 2017-10-26   NaN   NaN  14.0\n",
       "2912 2017-10-27   NaN   NaN   9.0\n",
       "2913 2017-10-28   NaN   NaN   4.0\n",
       "\n",
       "[2914 rows x 4 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>pm25</th>\n",
       "      <th>pm10</th>\n",
       "      <th>no2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-11-01</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-11-02</td>\n",
       "      <td>22.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-11-03</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-11-04</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-11-05</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2909</th>\n",
       "      <td>2017-10-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2910</th>\n",
       "      <td>2017-10-25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2911</th>\n",
       "      <td>2017-10-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2912</th>\n",
       "      <td>2017-10-27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2913</th>\n",
       "      <td>2017-10-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2914 rows √ó 4 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "id": "ec6aa8a024434e8b",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üåç STEP 6: Data cleaning</span>\n",
    "\n",
    "\n",
    "### Rename columns if needed and drop unneccessary columns\n",
    "\n",
    "We want to have a DataFrame with 2 columns - `date` and `pm25` after this cell below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14de8aaff3c9fdb5",
   "metadata": {},
   "source": [
    "## Check the data types for the columns in your DataFrame\n",
    "\n",
    " * `date` should be of type   datetime64[ns] \n",
    " * `pm25` should be of type float64"
   ]
  },
  {
   "cell_type": "code",
   "id": "1e4427c367e4ea2d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T12:02:39.005523Z",
     "start_time": "2025-11-14T12:02:38.986388Z"
    }
   },
   "source": [
    "df_aq = df[['date', 'pm25']]\n",
    "df_aq['pm25'] = df_aq['pm25'].astype('float32')\n",
    "\n",
    "df_aq"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "           date  pm25\n",
       "0    2025-11-01   9.0\n",
       "1    2025-11-02  22.0\n",
       "2    2025-11-03  14.0\n",
       "3    2025-11-04  10.0\n",
       "4    2025-11-05  15.0\n",
       "...         ...   ...\n",
       "2909 2017-10-24   NaN\n",
       "2910 2017-10-25   NaN\n",
       "2911 2017-10-26   NaN\n",
       "2912 2017-10-27   NaN\n",
       "2913 2017-10-28   NaN\n",
       "\n",
       "[2914 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>pm25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-11-01</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-11-02</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-11-03</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-11-04</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-11-05</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2909</th>\n",
       "      <td>2017-10-24</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2910</th>\n",
       "      <td>2017-10-25</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2911</th>\n",
       "      <td>2017-10-26</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2912</th>\n",
       "      <td>2017-10-27</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2913</th>\n",
       "      <td>2017-10-28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2914 rows √ó 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "id": "3a5fdc81411a81d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T12:02:39.690350Z",
     "start_time": "2025-11-14T12:02:39.681323Z"
    }
   },
   "source": [
    "# Cast the pm25 column to be a float32 data type\n",
    "df_aq.info()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2914 entries, 0 to 2913\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype         \n",
      "---  ------  --------------  -----         \n",
      " 0   date    2914 non-null   datetime64[ns]\n",
      " 1   pm25    2874 non-null   float32       \n",
      "dtypes: datetime64[ns](1), float32(1)\n",
      "memory usage: 34.3 KB\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "id": "ea71f6f2d0ccb812",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üåç STEP 7: Drop any rows with missing data </span>\n",
    "It will make the model training easier if there is no missing data in the rows, so we drop any rows with missing data."
   ]
  },
  {
   "cell_type": "code",
   "id": "c4ea64cd00e77857",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T12:02:39.947763Z",
     "start_time": "2025-11-14T12:02:39.933366Z"
    }
   },
   "source": [
    "df_aq.dropna(inplace=True)\n",
    "df_aq"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "           date  pm25\n",
       "0    2025-11-01   9.0\n",
       "1    2025-11-02  22.0\n",
       "2    2025-11-03  14.0\n",
       "3    2025-11-04  10.0\n",
       "4    2025-11-05  15.0\n",
       "...         ...   ...\n",
       "2869 2017-12-26  16.0\n",
       "2870 2017-12-27  10.0\n",
       "2871 2017-12-28  55.0\n",
       "2872 2017-12-29  42.0\n",
       "2873 2017-12-30  16.0\n",
       "\n",
       "[2874 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>pm25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-11-01</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-11-02</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-11-03</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-11-04</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-11-05</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2869</th>\n",
       "      <td>2017-12-26</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2870</th>\n",
       "      <td>2017-12-27</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2871</th>\n",
       "      <td>2017-12-28</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2872</th>\n",
       "      <td>2017-12-29</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2873</th>\n",
       "      <td>2017-12-30</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2874 rows √ó 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "cell_type": "markdown",
   "id": "1a4423f11a14afdc",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üåç STEP 8: Add country, city, street, url to the DataFrame </span>\n",
    "\n",
    "Your CSV file may have many other air quality measurement columns. We will only work with the `pm25` column.\n",
    "\n",
    "We add the columns for the country, city, and street names that you changed for your Air Quality sensor.\n",
    "\n",
    "We also want to make sure the `pm25` column is a float32 data type."
   ]
  },
  {
   "cell_type": "code",
   "id": "25b30ba9b1767c51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T12:02:41.056571Z",
     "start_time": "2025-11-14T12:02:41.039337Z"
    }
   },
   "source": [
    "# Your sensor may have columns we won't use, so only keep the date and pm25 columns\n",
    "# If the column names in your DataFrame are different, rename your columns to `date` and `pm25`\n",
    "df_aq['country']=country\n",
    "df_aq['city']=city\n",
    "df_aq['street']=street\n",
    "df_aq['url']=aqicn_url\n",
    "df_aq"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "           date  pm25 country       city          street  \\\n",
       "0    2025-11-01   9.0  Sweden  Stockholm  Hornsgatan-108   \n",
       "1    2025-11-02  22.0  Sweden  Stockholm  Hornsgatan-108   \n",
       "2    2025-11-03  14.0  Sweden  Stockholm  Hornsgatan-108   \n",
       "3    2025-11-04  10.0  Sweden  Stockholm  Hornsgatan-108   \n",
       "4    2025-11-05  15.0  Sweden  Stockholm  Hornsgatan-108   \n",
       "...         ...   ...     ...        ...             ...   \n",
       "2869 2017-12-26  16.0  Sweden  Stockholm  Hornsgatan-108   \n",
       "2870 2017-12-27  10.0  Sweden  Stockholm  Hornsgatan-108   \n",
       "2871 2017-12-28  55.0  Sweden  Stockholm  Hornsgatan-108   \n",
       "2872 2017-12-29  42.0  Sweden  Stockholm  Hornsgatan-108   \n",
       "2873 2017-12-30  16.0  Sweden  Stockholm  Hornsgatan-108   \n",
       "\n",
       "                                    url  \n",
       "0     https://api.waqi.info/feed/@10009  \n",
       "1     https://api.waqi.info/feed/@10009  \n",
       "2     https://api.waqi.info/feed/@10009  \n",
       "3     https://api.waqi.info/feed/@10009  \n",
       "4     https://api.waqi.info/feed/@10009  \n",
       "...                                 ...  \n",
       "2869  https://api.waqi.info/feed/@10009  \n",
       "2870  https://api.waqi.info/feed/@10009  \n",
       "2871  https://api.waqi.info/feed/@10009  \n",
       "2872  https://api.waqi.info/feed/@10009  \n",
       "2873  https://api.waqi.info/feed/@10009  \n",
       "\n",
       "[2874 rows x 6 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>pm25</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>street</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-11-01</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>Hornsgatan-108</td>\n",
       "      <td>https://api.waqi.info/feed/@10009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-11-02</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>Hornsgatan-108</td>\n",
       "      <td>https://api.waqi.info/feed/@10009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-11-03</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>Hornsgatan-108</td>\n",
       "      <td>https://api.waqi.info/feed/@10009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-11-04</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>Hornsgatan-108</td>\n",
       "      <td>https://api.waqi.info/feed/@10009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-11-05</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>Hornsgatan-108</td>\n",
       "      <td>https://api.waqi.info/feed/@10009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2869</th>\n",
       "      <td>2017-12-26</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>Hornsgatan-108</td>\n",
       "      <td>https://api.waqi.info/feed/@10009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2870</th>\n",
       "      <td>2017-12-27</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>Hornsgatan-108</td>\n",
       "      <td>https://api.waqi.info/feed/@10009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2871</th>\n",
       "      <td>2017-12-28</td>\n",
       "      <td>55.0</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>Hornsgatan-108</td>\n",
       "      <td>https://api.waqi.info/feed/@10009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2872</th>\n",
       "      <td>2017-12-29</td>\n",
       "      <td>42.0</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>Hornsgatan-108</td>\n",
       "      <td>https://api.waqi.info/feed/@10009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2873</th>\n",
       "      <td>2017-12-30</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>Hornsgatan-108</td>\n",
       "      <td>https://api.waqi.info/feed/@10009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2874 rows √ó 6 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "cell_type": "markdown",
   "id": "q3vxm9iipie",
   "source": "## <span style='color:#ff5f27'> üîÑ Add Lagged Features </span>\n\nWe will add lagged PM2.5 features (1, 2, and 3 days ago) to improve model predictions. Historical air quality is a strong predictor of future air quality.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "ps70vbqlmi",
   "source": "# Sort by date to ensure proper lag calculation\ndf_aq = df_aq.sort_values('date').reset_index(drop=True)\n\n# Create lagged features (1, 2, and 3 days)\ndf_aq['pm25_lag_1d'] = df_aq['pm25'].shift(1)\ndf_aq['pm25_lag_2d'] = df_aq['pm25'].shift(2)\ndf_aq['pm25_lag_3d'] = df_aq['pm25'].shift(3)\n\n# Drop the first 3 rows with NaN lagged values\ndf_aq = df_aq.dropna()\n\nprint(f\"‚úÖ Added lagged features: pm25_lag_1d, pm25_lag_2d, pm25_lag_3d\")\nprint(f\"Dataset shape after adding lagged features: {df_aq.shape}\")\nprint(f\"\\nSample of lagged features:\")\ndf_aq[['date', 'pm25', 'pm25_lag_1d', 'pm25_lag_2d', 'pm25_lag_3d']].head(10)",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T12:02:41.262939Z",
     "start_time": "2025-11-14T12:02:41.233084Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Added lagged features: pm25_lag_1d, pm25_lag_2d, pm25_lag_3d\n",
      "Dataset shape after adding lagged features: (2871, 9)\n",
      "\n",
      "Sample of lagged features:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "         date  pm25  pm25_lag_1d  pm25_lag_2d  pm25_lag_3d\n",
       "3  2017-10-07  13.0          8.0          9.0         13.0\n",
       "4  2017-10-08   8.0         13.0          8.0          9.0\n",
       "5  2017-10-09   7.0          8.0         13.0          8.0\n",
       "6  2017-10-10  12.0          7.0          8.0         13.0\n",
       "7  2017-10-11  12.0         12.0          7.0          8.0\n",
       "8  2017-10-12  10.0         12.0         12.0          7.0\n",
       "9  2017-10-13   9.0         10.0         12.0         12.0\n",
       "10 2017-10-14  11.0          9.0         10.0         12.0\n",
       "11 2017-10-15  21.0         11.0          9.0         10.0\n",
       "12 2017-10-16  28.0         21.0         11.0          9.0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>pm25</th>\n",
       "      <th>pm25_lag_1d</th>\n",
       "      <th>pm25_lag_2d</th>\n",
       "      <th>pm25_lag_3d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-10-07</td>\n",
       "      <td>13.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-10-08</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2017-10-09</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2017-10-10</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2017-10-11</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2017-10-12</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017-10-13</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2017-10-14</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2017-10-15</td>\n",
       "      <td>21.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2017-10-16</td>\n",
       "      <td>28.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "id": "7a7900f1cefe7ba9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T12:02:41.729724Z",
     "start_time": "2025-11-14T12:02:41.719957Z"
    }
   },
   "source": [
    "df_aq.info()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2871 entries, 3 to 2873\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count  Dtype         \n",
      "---  ------       --------------  -----         \n",
      " 0   date         2871 non-null   datetime64[ns]\n",
      " 1   pm25         2871 non-null   float32       \n",
      " 2   country      2871 non-null   object        \n",
      " 3   city         2871 non-null   object        \n",
      " 4   street       2871 non-null   object        \n",
      " 5   url          2871 non-null   object        \n",
      " 6   pm25_lag_1d  2871 non-null   float32       \n",
      " 7   pm25_lag_2d  2871 non-null   float32       \n",
      " 8   pm25_lag_3d  2871 non-null   float32       \n",
      "dtypes: datetime64[ns](1), float32(4), object(4)\n",
      "memory usage: 179.4+ KB\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "cell_type": "markdown",
   "id": "a110aba37978b5e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2708d48684e2ff",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üå¶ Loading Weather Data from [Open Meteo](https://open-meteo.com/en/docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5b32a0dcb8e8ed",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üåç STEP 9: Download the Historical Weather Data </span>\n",
    "\n",
    "https://open-meteo.com/en/docs/historical-weather-api#hourly=&daily=temperature_2m_mean,precipitation_sum,wind_speed_10m_max,wind_direction_10m_dominant\n",
    "\n",
    "We will download the historical weather data for your `city` by first extracting the earliest date from your DataFrame containing the historical air quality measurements.\n",
    "\n",
    "We will download all daily historical weather data measurements for your `city` from the earliest date in your air quality measurement DataFrame. It doesn't matter if there are missing days of air quality measurements. We can store all of the daily weather measurements, and when we build our training dataset, we will join up the air quality measurements for a given day to its weather features for that day. \n",
    "\n",
    "The weather features we will download are:\n",
    "\n",
    " * `temperature (average over the day)`\n",
    " * `precipitation (the total over the day)`\n",
    " * `wind speed (average over the day)`\n",
    " * `wind direction (the most dominant direction over the day)`\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "2aebc659bcf629a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T12:02:41.880909Z",
     "start_time": "2025-11-14T12:02:41.863961Z"
    }
   },
   "source": [
    "earliest_aq_date = pd.Series.min(df_aq['date'])\n",
    "earliest_aq_date = earliest_aq_date.strftime('%Y-%m-%d')\n",
    "earliest_aq_date\n",
    "\n",
    "weather_df = util.get_historical_weather(city, earliest_aq_date, str(today), latitude, longitude)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinates 59.29701232910156¬∞N 18.163265228271484¬∞E\n",
      "Elevation 18.0 m asl\n",
      "Timezone None None\n",
      "Timezone difference to GMT+0 0 s\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "id": "6529bfa678250441",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T12:02:42.045705Z",
     "start_time": "2025-11-14T12:02:42.033103Z"
    }
   },
   "source": [
    "weather_df.info()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2961 entries, 0 to 2960\n",
      "Data columns (total 6 columns):\n",
      " #   Column                       Non-Null Count  Dtype         \n",
      "---  ------                       --------------  -----         \n",
      " 0   date                         2961 non-null   datetime64[ns]\n",
      " 1   temperature_2m_mean          2961 non-null   float32       \n",
      " 2   precipitation_sum            2961 non-null   float32       \n",
      " 3   wind_speed_10m_max           2961 non-null   float32       \n",
      " 4   wind_direction_10m_dominant  2961 non-null   float32       \n",
      " 5   city                         2961 non-null   object        \n",
      "dtypes: datetime64[ns](1), float32(4), object(1)\n",
      "memory usage: 92.7+ KB\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "cell_type": "markdown",
   "id": "3f3ce694aecb4060",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üåç STEP 10: Define Data Validation Rules </span>\n",
    "\n",
    "We will validate the air quality measurements (`pm25` values) before we write them to Hopsworks.\n",
    "\n",
    "We define a data validation rule (an expectation in Great Expectations) that ensures that `pm25` values are not negative or above the max value available by the sensor.\n",
    "\n",
    "We will attach this expectation to the air quality feature group, so that we validate the `pm25` data every time we write a DataFrame to the feature group. We want to prevent garbage-in, garbage-out."
   ]
  },
  {
   "cell_type": "code",
   "id": "c7b6d59008423787",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T12:02:42.081794Z",
     "start_time": "2025-11-14T12:02:42.073351Z"
    }
   },
   "source": [
    "import great_expectations as ge\n",
    "aq_expectation_suite = ge.core.ExpectationSuite(\n",
    "    expectation_suite_name=\"aq_expectation_suite\"\n",
    ")\n",
    "\n",
    "aq_expectation_suite.add_expectation(\n",
    "    ge.core.ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_min_to_be_between\",\n",
    "        kwargs={\n",
    "            \"column\":\"pm25\",\n",
    "            \"min_value\":-0.1,\n",
    "            \"max_value\":500.0,\n",
    "            \"strict_min\":True\n",
    "        }\n",
    "    )\n",
    ")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"expectation_type\": \"expect_column_min_to_be_between\", \"kwargs\": {\"column\": \"pm25\", \"min_value\": -0.1, \"max_value\": 500.0, \"strict_min\": true}, \"meta\": {}}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 39
  },
  {
   "cell_type": "markdown",
   "id": "124619babe886341",
   "metadata": {},
   "source": [
    "## Expectations for Weather Data\n",
    "Here, we define an expectation for 2 columns in our weather DataFrame - `precipitation_sum` and `wind_speed_10m_max`, where we expect both values to be greater than zero, but less than 1000."
   ]
  },
  {
   "cell_type": "code",
   "id": "bcba8bb51036f4b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T12:02:42.138194Z",
     "start_time": "2025-11-14T12:02:42.131373Z"
    }
   },
   "source": [
    "import great_expectations as ge\n",
    "weather_expectation_suite = ge.core.ExpectationSuite(\n",
    "    expectation_suite_name=\"weather_expectation_suite\"\n",
    ")\n",
    "\n",
    "def expect_greater_than_zero(col):\n",
    "    weather_expectation_suite.add_expectation(\n",
    "        ge.core.ExpectationConfiguration(\n",
    "            expectation_type=\"expect_column_min_to_be_between\",\n",
    "            kwargs={\n",
    "                \"column\":col,\n",
    "                \"min_value\":-0.1,\n",
    "                \"max_value\":1000.0,\n",
    "                \"strict_min\":True\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "expect_greater_than_zero(\"precipitation_sum\")\n",
    "expect_greater_than_zero(\"wind_speed_10m_max\")"
   ],
   "outputs": [],
   "execution_count": 40
  },
  {
   "cell_type": "markdown",
   "id": "4cf8a4d349a430fe",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fdccde92d3c23b1",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\"> üîÆ STEP 11: Connect to Hopsworks and save the sensor country, city, street names as a secret</span>"
   ]
  },
  {
   "cell_type": "code",
   "id": "1918ca1537b2e3bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T12:02:42.445766Z",
     "start_time": "2025-11-14T12:02:42.197657Z"
    }
   },
   "source": [
    "fs = project.get_feature_store() "
   ],
   "outputs": [],
   "execution_count": 41
  },
  {
   "cell_type": "markdown",
   "id": "1bca68770ac9533",
   "metadata": {},
   "source": [
    "#### Save country, city, street names as a secret\n",
    "\n",
    "These will be downloaded from Hopsworks later in the (1) daily feature pipeline and (2) the daily batch inference pipeline"
   ]
  },
  {
   "cell_type": "code",
   "id": "d4cd1a968bc87f61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T12:02:43.267218Z",
     "start_time": "2025-11-14T12:02:42.460544Z"
    }
   },
   "source": [
    "dict_obj = {\n",
    "    \"country\": country,\n",
    "    \"city\": city,\n",
    "    \"street\": street,\n",
    "    \"aqicn_url\": aqicn_url,\n",
    "    \"latitude\": latitude,\n",
    "    \"longitude\": longitude\n",
    "}\n",
    "\n",
    "# Convert the dictionary to a JSON string\n",
    "str_dict = json.dumps(dict_obj)\n",
    "\n",
    "# Replace any existing secret with the new value\n",
    "secret = secrets.get_secret(\"SENSOR_LOCATION_JSON\")\n",
    "if secret is not None:\n",
    "    secret.delete()\n",
    "    print(\"Replacing existing SENSOR_LOCATION_JSON\")\n",
    "\n",
    "secrets.create_secret(\"SENSOR_LOCATION_JSON\", str_dict)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacing existing SENSOR_LOCATION_JSON\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Secret('SENSOR_LOCATION_JSON', 'PRIVATE')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "cell_type": "markdown",
   "id": "c81ce4b9f81d6748",
   "metadata": {},
   "source": "### <span style=\"color:#ff5f27;\"> üîÆ STEP 12: Create the Feature Groups and insert the DataFrames in them </span>\n\n**Note:** We're creating **version 2** of the `air_quality` feature group to include the new lagged PM2.5 features. This allows us to keep the old version (v1) intact while adding the new schema with lagged features."
  },
  {
   "cell_type": "markdown",
   "id": "8e463c571da9974c",
   "metadata": {},
   "source": [
    "### <span style='color:#ff5f27'> üå´ Air Quality Data\n",
    "    \n",
    " 1. Provide a name, description, and version for the feature group.\n",
    " 2. Define the `primary_key`: we have to select which columns uniquely identify each row in the DataFrame - by providing them as the `primary_key`. Here, each air quality sensor measurement is uniquely identified by `country`, `street`, and  `date`.\n",
    " 3. Define the `event_time`: We also define which column stores the timestamp or date for the row - `date`.\n",
    " 4. Attach any `expectation_suite` containing data validation rules"
   ]
  },
  {
   "cell_type": "code",
   "id": "db5f615ad2b88614",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T12:02:43.571775Z",
     "start_time": "2025-11-14T12:02:43.331310Z"
    }
   },
   "source": "air_quality_fg = fs.get_or_create_feature_group(\n    name='air_quality',\n    description='Air Quality characteristics of each day with lagged PM2.5 features',\n    version=2,  # Incremented version to include lagged features\n    primary_key=['country','city', 'street'],\n    event_time=\"date\",\n    expectation_suite=aq_expectation_suite\n)",
   "outputs": [],
   "execution_count": 43
  },
  {
   "cell_type": "markdown",
   "id": "ac27063d58676851",
   "metadata": {},
   "source": [
    "#### Insert the DataFrame into the Feature Group"
   ]
  },
  {
   "cell_type": "code",
   "id": "4c5fe7bcae99fadf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T12:03:02.002968Z",
     "start_time": "2025-11-14T12:02:43.583575Z"
    }
   },
   "source": [
    "air_quality_fg.insert(df_aq)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Group created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/1279143/fs/1265751/fg/1668887\n",
      "2025-11-14 13:02:46,133 INFO: \t1 expectation(s) included in expectation_suite.\n",
      "Validation succeeded.\n",
      "Validation Report saved successfully, explore a summary at https://c.app.hopsworks.ai:443/p/1279143/fs/1265751/fg/1668887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| Rows 2871/2871 | Elapsed Time: 00:02 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: air_quality_2_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1279143/jobs/named/air_quality_2_offline_fg_materialization/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Job('air_quality_2_offline_fg_materialization', 'SPARK'),\n",
       " {\n",
       "   \"success\": true,\n",
       "   \"results\": [\n",
       "     {\n",
       "       \"success\": true,\n",
       "       \"expectation_config\": {\n",
       "         \"expectation_type\": \"expect_column_min_to_be_between\",\n",
       "         \"kwargs\": {\n",
       "           \"column\": \"pm25\",\n",
       "           \"min_value\": -0.1,\n",
       "           \"max_value\": 500.0,\n",
       "           \"strict_min\": true\n",
       "         },\n",
       "         \"meta\": {\n",
       "           \"expectationId\": 739523\n",
       "         }\n",
       "       },\n",
       "       \"result\": {\n",
       "         \"observed_value\": 4.0,\n",
       "         \"element_count\": 2871,\n",
       "         \"missing_count\": null,\n",
       "         \"missing_percent\": null\n",
       "       },\n",
       "       \"meta\": {\n",
       "         \"ingestionResult\": \"INGESTED\",\n",
       "         \"validationTime\": \"2025-11-14T12:02:46.000132Z\"\n",
       "       },\n",
       "       \"exception_info\": {\n",
       "         \"raised_exception\": false,\n",
       "         \"exception_message\": null,\n",
       "         \"exception_traceback\": null\n",
       "       }\n",
       "     }\n",
       "   ],\n",
       "   \"evaluation_parameters\": {},\n",
       "   \"statistics\": {\n",
       "     \"evaluated_expectations\": 1,\n",
       "     \"successful_expectations\": 1,\n",
       "     \"unsuccessful_expectations\": 0,\n",
       "     \"success_percent\": 100.0\n",
       "   },\n",
       "   \"meta\": {\n",
       "     \"great_expectations_version\": \"0.18.12\",\n",
       "     \"expectation_suite_name\": \"aq_expectation_suite\",\n",
       "     \"run_id\": {\n",
       "       \"run_name\": null,\n",
       "       \"run_time\": \"2025-11-14T13:02:46.132914+01:00\"\n",
       "     },\n",
       "     \"batch_kwargs\": {\n",
       "       \"ge_batch_id\": \"d52a5208-c151-11f0-8804-e4601782813d\"\n",
       "     },\n",
       "     \"batch_markers\": {},\n",
       "     \"batch_parameters\": {},\n",
       "     \"validation_time\": \"20251114T120246.132785Z\",\n",
       "     \"expectation_suite_meta\": {\n",
       "       \"great_expectations_version\": \"0.18.12\"\n",
       "     }\n",
       "   }\n",
       " })"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 44
  },
  {
   "cell_type": "markdown",
   "id": "f737a3da9136ef48",
   "metadata": {},
   "source": [
    "#### Enter a description for each feature in the Feature Group"
   ]
  },
  {
   "cell_type": "code",
   "id": "a5fec7267c402134",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T12:03:07.326625Z",
     "start_time": "2025-11-14T12:03:02.074950Z"
    }
   },
   "source": "air_quality_fg.update_feature_description(\"date\", \"Date of measurement of air quality\")\nair_quality_fg.update_feature_description(\"country\", \"Country where the air quality was measured (sometimes a city in acqcn.org)\")\nair_quality_fg.update_feature_description(\"city\", \"City where the air quality was measured\")\nair_quality_fg.update_feature_description(\"street\", \"Street in the city where the air quality was measured\")\nair_quality_fg.update_feature_description(\"pm25\", \"Particles less than 2.5 micrometers in diameter (fine particles) pose health risk\")\nair_quality_fg.update_feature_description(\"pm25_lag_1d\", \"PM2.5 measurement from 1 day ago\")\nair_quality_fg.update_feature_description(\"pm25_lag_2d\", \"PM2.5 measurement from 2 days ago\")\nair_quality_fg.update_feature_description(\"pm25_lag_3d\", \"PM2.5 measurement from 3 days ago\")",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<hsfs.feature_group.FeatureGroup at 0x70c2bc716d10>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 45
  },
  {
   "cell_type": "markdown",
   "id": "ad548cc8f098981",
   "metadata": {},
   "source": [
    "### <span style='color:#ff5f27'> üå¶ Weather Data\n",
    "    \n",
    " 1. Provide a name, description, and version for the feature group.\n",
    " 2. Define the `primary_key`: we have to select which columns uniquely identify each row in the DataFrame - by providing them as the `primary_key`. Here, each weather measurement is uniquely identified by `city` and  `date`.\n",
    " 3. Define the `event_time`: We also define which column stores the timestamp or date for the row - `date`.\n",
    " 4. Attach any `expectation_suite` containing data validation rules"
   ]
  },
  {
   "cell_type": "code",
   "id": "11bfebdb69632318",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T12:03:07.944799Z",
     "start_time": "2025-11-14T12:03:07.388313Z"
    }
   },
   "source": [
    "# Get or create feature group \n",
    "weather_fg = fs.get_or_create_feature_group(\n",
    "    name='weather',\n",
    "    description='Weather characteristics of each day',\n",
    "    version=1,\n",
    "    primary_key=['city'],\n",
    "    event_time=\"date\",\n",
    "    expectation_suite=weather_expectation_suite\n",
    ") "
   ],
   "outputs": [],
   "execution_count": 46
  },
  {
   "cell_type": "markdown",
   "id": "8cb4ded6adf37b26",
   "metadata": {},
   "source": [
    "#### Insert the DataFrame into the Feature Group"
   ]
  },
  {
   "cell_type": "code",
   "id": "2162d9b0dbffe4e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T12:05:31.962466Z",
     "start_time": "2025-11-14T12:03:07.961465Z"
    }
   },
   "source": [
    "# Insert data\n",
    "weather_fg.insert(weather_df, wait=True)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-14 13:03:08,156 INFO: \t2 expectation(s) included in expectation_suite.\n",
      "Validation succeeded.\n",
      "Validation Report saved successfully, explore a summary at https://c.app.hopsworks.ai:443/p/1279143/fs/1265751/fg/1637909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| Rows 2961/2961 | Elapsed Time: 00:02 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: weather_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1279143/jobs/named/weather_1_offline_fg_materialization/executions\n",
      "2025-11-14 13:03:26,692 INFO: Waiting for execution to finish. Current state: SUBMITTED. Final status: UNDEFINED\n",
      "2025-11-14 13:03:29,882 INFO: Waiting for execution to finish. Current state: RUNNING. Final status: UNDEFINED\n",
      "2025-11-14 13:05:09,388 INFO: Waiting for execution to finish. Current state: AGGREGATING_LOGS. Final status: SUCCEEDED\n",
      "2025-11-14 13:05:09,593 INFO: Waiting for log aggregation to finish.\n",
      "2025-11-14 13:05:31,955 INFO: Execution finished successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Job('weather_1_offline_fg_materialization', 'SPARK'),\n",
       " {\n",
       "   \"success\": true,\n",
       "   \"results\": [\n",
       "     {\n",
       "       \"success\": true,\n",
       "       \"expectation_config\": {\n",
       "         \"expectation_type\": \"expect_column_min_to_be_between\",\n",
       "         \"kwargs\": {\n",
       "           \"column\": \"precipitation_sum\",\n",
       "           \"min_value\": -0.1,\n",
       "           \"max_value\": 1000.0,\n",
       "           \"strict_min\": true\n",
       "         },\n",
       "         \"meta\": {\n",
       "           \"expectationId\": 735305\n",
       "         }\n",
       "       },\n",
       "       \"result\": {\n",
       "         \"observed_value\": 0.0,\n",
       "         \"element_count\": 2961,\n",
       "         \"missing_count\": null,\n",
       "         \"missing_percent\": null\n",
       "       },\n",
       "       \"meta\": {\n",
       "         \"ingestionResult\": \"INGESTED\",\n",
       "         \"validationTime\": \"2025-11-14T12:03:08.000155Z\"\n",
       "       },\n",
       "       \"exception_info\": {\n",
       "         \"raised_exception\": false,\n",
       "         \"exception_message\": null,\n",
       "         \"exception_traceback\": null\n",
       "       }\n",
       "     },\n",
       "     {\n",
       "       \"success\": true,\n",
       "       \"expectation_config\": {\n",
       "         \"expectation_type\": \"expect_column_min_to_be_between\",\n",
       "         \"kwargs\": {\n",
       "           \"column\": \"wind_speed_10m_max\",\n",
       "           \"min_value\": -0.1,\n",
       "           \"max_value\": 1000.0,\n",
       "           \"strict_min\": true\n",
       "         },\n",
       "         \"meta\": {\n",
       "           \"expectationId\": 735306\n",
       "         }\n",
       "       },\n",
       "       \"result\": {\n",
       "         \"observed_value\": 3.41525936126709,\n",
       "         \"element_count\": 2961,\n",
       "         \"missing_count\": null,\n",
       "         \"missing_percent\": null\n",
       "       },\n",
       "       \"meta\": {\n",
       "         \"ingestionResult\": \"INGESTED\",\n",
       "         \"validationTime\": \"2025-11-14T12:03:08.000155Z\"\n",
       "       },\n",
       "       \"exception_info\": {\n",
       "         \"raised_exception\": false,\n",
       "         \"exception_message\": null,\n",
       "         \"exception_traceback\": null\n",
       "       }\n",
       "     }\n",
       "   ],\n",
       "   \"evaluation_parameters\": {},\n",
       "   \"statistics\": {\n",
       "     \"evaluated_expectations\": 2,\n",
       "     \"successful_expectations\": 2,\n",
       "     \"unsuccessful_expectations\": 0,\n",
       "     \"success_percent\": 100.0\n",
       "   },\n",
       "   \"meta\": {\n",
       "     \"great_expectations_version\": \"0.18.12\",\n",
       "     \"expectation_suite_name\": \"weather_expectation_suite\",\n",
       "     \"run_id\": {\n",
       "       \"run_name\": null,\n",
       "       \"run_time\": \"2025-11-14T13:03:08.155729+01:00\"\n",
       "     },\n",
       "     \"batch_kwargs\": {\n",
       "       \"ge_batch_id\": \"e24ac062-c151-11f0-8804-e4601782813d\"\n",
       "     },\n",
       "     \"batch_markers\": {},\n",
       "     \"batch_parameters\": {},\n",
       "     \"validation_time\": \"20251114T120308.155601Z\",\n",
       "     \"expectation_suite_meta\": {\n",
       "       \"great_expectations_version\": \"0.18.12\"\n",
       "     }\n",
       "   }\n",
       " })"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 47
  },
  {
   "cell_type": "markdown",
   "id": "a34b3a88c69625bf",
   "metadata": {},
   "source": [
    "#### Enter a description for each feature in the Feature Group"
   ]
  },
  {
   "cell_type": "code",
   "id": "7b6c4572abeba1ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T12:05:35.913640Z",
     "start_time": "2025-11-14T12:05:32.089130Z"
    }
   },
   "source": [
    "weather_fg.update_feature_description(\"date\", \"Date of measurement of weather\")\n",
    "weather_fg.update_feature_description(\"city\", \"City where weather is measured/forecast for\")\n",
    "weather_fg.update_feature_description(\"temperature_2m_mean\", \"Temperature in Celsius\")\n",
    "weather_fg.update_feature_description(\"precipitation_sum\", \"Precipitation (rain/snow) in mm\")\n",
    "weather_fg.update_feature_description(\"wind_speed_10m_max\", \"Wind speed at 10m abouve ground\")\n",
    "weather_fg.update_feature_description(\"wind_direction_10m_dominant\", \"Dominant Wind direction over the dayd\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<hsfs.feature_group.FeatureGroup at 0x70c1b0039510>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 48
  },
  {
   "cell_type": "markdown",
   "id": "2ad59e92b8d3bd8c",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\">‚è≠Ô∏è **Next:** Part 02: Daily Feature Pipeline \n",
    " </span> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc95c60fe00f031",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\">‚è≠Ô∏è **Exercises:** \n",
    " </span> \n",
    "\n",
    "Extra Homework:\n",
    "\n",
    "  * Try adding a new feature based on a rolling window of 3 days for 'pm25'\n",
    "      * This is not easy, as forecasting more than 1 day in the future, you won't have the previous 3 days of pm25 measurements.\n",
    "      * df.set_index(\"date\").rolling(3).mean() is only the start....\n",
    "  * Parameterize the notebook, so that you can provide the `country`/`street`/`city`/`url`/`csv_file` as parameters. \n",
    "      * Hint: this will also require making the secret name (`SENSOR_LOCATION_JSON`), e.g., add the street name as part of the secret name. Then you have to pass that secret name as a parameter when running the operational feature pipeline and batch inference pipelines.\n",
    "      * After you have done this, collect the street/city/url/csv files for all the sensors in your city or region and you make dashboards for all of the air quality sensors in your city/region. You could even then add a dashboard for your city/region, as done [here for Poland](https://github.com/erno98/ID2223).\n",
    "\n",
    "Improve this AI System\n",
    "  * As of mid 2024, there is no API call available to download historical data from the AQIN website. You could improve this system by writing a PR to download the CSV file using Python Selenium and the URL for the sensor.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54dba3982b603d1",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
