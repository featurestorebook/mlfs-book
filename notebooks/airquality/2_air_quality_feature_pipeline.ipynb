{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4447764c-218b-441a-ab97-4df4062960d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "def is_google_colab() -> bool:\n",
    "    if \"google.colab\" in str(get_ipython()):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def clone_repository() -> None:\n",
    "    !git clone https://github.com/featurestorebook/mlfs-book.git\n",
    "    %cd mlfs-book\n",
    "\n",
    "def install_dependencies() -> None:\n",
    "    !pip install --upgrade uv\n",
    "    !uv pip install --all-extras --system --requirement pyproject.toml\n",
    "\n",
    "if is_google_colab():\n",
    "    clone_repository()\n",
    "    install_dependencies()\n",
    "    root_dir = str(Path().absolute())\n",
    "    print(\"Google Colab environment\")\n",
    "else:\n",
    "    root_dir = Path().absolute()\n",
    "    # Strip ~/notebooks/ccfraud from PYTHON_PATH if notebook started in one of these subdirectories\n",
    "    if root_dir.parts[-1:] == ('airquality',):\n",
    "        root_dir = Path(*root_dir.parts[:-1])\n",
    "    if root_dir.parts[-1:] == ('notebooks',):\n",
    "        root_dir = Path(*root_dir.parts[:-1])\n",
    "    root_dir = str(root_dir) \n",
    "    print(\"Local environment\")\n",
    "\n",
    "# Add the root directory to the `PYTHONPATH` to use the `recsys` Python module from the notebook.\n",
    "if root_dir not in sys.path:\n",
    "    sys.path.append(root_dir)\n",
    "print(f\"Added the following directory to the PYTHONPATH: {root_dir}\")\n",
    "    \n",
    "# Set the environment variables from the file <root_dir>/.env\n",
    "# from mlfs import config\n",
    "# settings = config.HopsworksSettings(_env_file=f\"{root_dir}/.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e46aad",
   "metadata": {},
   "source": [
    "<span style=\"font-width:bold; font-size: 3rem; color:#333;\">- Part 02: Daily Feature Pipeline for Air Quality (aqicn.org) and weather (openmeteo)</span>\n",
    "\n",
    "## üóíÔ∏è This notebook is divided into the following sections:\n",
    "1. Download and Parse Data\n",
    "2. Feature Group Insertion\n",
    "\n",
    "\n",
    "__This notebook should be scheduled to run daily__\n",
    "\n",
    "In the book, we use a GitHub Action stored here:\n",
    "[.github/workflows/air-quality-daily.yml](https://github.com/featurestorebook/mlfs-book/blob/main/.github/workflows/air-quality-daily.yml)\n",
    "\n",
    "However, you are free to use any Python Orchestration tool to schedule this program to run daily."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe638c6",
   "metadata": {},
   "source": [
    "### <span style='color:#ff5f27'> üìù Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de2e93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from datetime import timedelta\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "import hopsworks\n",
    "from mlfs.airquality import util\n",
    "from mlfs import config\n",
    "import json\n",
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6081d1",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üåç Get the Sensor URL, Country, City, Street names from Hopsworks </span>\n",
    "\n",
    "__Update the values in the cell below.__\n",
    "\n",
    "__These should be the same values as in notebook 1 - the feature backfill notebook__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70cd57d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "project = hopsworks.login(engine=\"python\")\n",
    "fs = project.get_feature_store() \n",
    "secrets = hopsworks.get_secrets_api()\n",
    "\n",
    "# This line will fail if you have not registered the AQICN_API_KEY as a secret in Hopsworks\n",
    "AQICN_API_KEY = secrets.get_secret(\"AQICN_API_KEY\").value\n",
    "location_str = secrets.get_secret(\"SENSOR_LOCATION_JSON\").value\n",
    "location = json.loads(location_str)\n",
    "\n",
    "country=location['country']\n",
    "city=location['city']\n",
    "street=location['street']\n",
    "aqicn_url=location['aqicn_url']\n",
    "latitude=location['latitude']\n",
    "longitude=location['longitude']\n",
    "\n",
    "today = datetime.date.today()\n",
    "\n",
    "location_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2caf9289",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\"> üîÆ Get references to the Feature Groups </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f5d7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve feature groups\n",
    "air_quality_fg = fs.get_feature_group(\n",
    "    name='air_quality',\n",
    "    version=1,\n",
    ")\n",
    "weather_fg = fs.get_feature_group(\n",
    "    name='weather',\n",
    "    version=1,\n",
    ")\n",
    "lagged_fg = fs.get_feature_group(\n",
    "    name='lagged_pm25',\n",
    "    version=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10b6ce8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7ffa41",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üå´ Retrieve Today's Air Quality data (PM2.5) from the AQI API</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f681af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "aq_today_df = util.get_pm25(aqicn_url, country, city, street, today, AQICN_API_KEY)\n",
    "aq_today_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e24eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "aq_today_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af845ab6",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üå¶ Get Weather Forecast data</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ecb3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_df = util.get_hourly_weather_forecast(city, latitude, longitude)\n",
    "hourly_df = hourly_df.set_index('date')\n",
    "hourly_df.dropna(inplace=True)\n",
    "\n",
    "\n",
    "# We will only make 1 daily prediction, so we will replace the hourly forecasts with a single daily forecast\n",
    "# We only want the daily weather data, so only get weather at 12:00\n",
    "daily_df = hourly_df.between_time('11:59', '12:01')\n",
    "daily_df = daily_df.reset_index()\n",
    "daily_df['date'] = pd.to_datetime(daily_df['date']).dt.date\n",
    "daily_df['date'] = pd.to_datetime(daily_df['date'])\n",
    "daily_df['city'] = city\n",
    "\n",
    "# Wind speed squared\n",
    "daily_df['wind_speed_10m_max_squared'] = daily_df['wind_speed_10m_max'] ** 2\n",
    "\n",
    "# Wind speed directions\n",
    "daily_df['wind_u'] = daily_df['wind_speed_10m_max'] * np.sin(np.radians(daily_df['wind_direction_10m_dominant']))\n",
    "daily_df['wind_v'] = daily_df['wind_speed_10m_max'] * np.cos(np.radians(daily_df['wind_direction_10m_dominant']))\n",
    "\n",
    "# Temporal signals\n",
    "daily_df['day_of_week'] = daily_df['date'].dt.dayofweek          # 0=Mon\n",
    "daily_df['month'] = daily_df['date'].dt.month\n",
    "daily_df['is_weekend'] = (daily_df['day_of_week'] >= 5).astype(int)\n",
    "daily_df['day_of_year'] = daily_df['date'].dt.dayofyear\n",
    "\n",
    "# Cyclical encoding for day/month so models ‚Äúfeel‚Äù seasonality\n",
    "daily_df['day_of_week_sin'] = np.sin(2 * np.pi * daily_df['day_of_week'] / 7)\n",
    "daily_df['day_of_week_cos'] = np.cos(2 * np.pi * daily_df['day_of_week'] / 7)\n",
    "daily_df['month_sin'] = np.sin(2 * np.pi * daily_df['month'] / 12)\n",
    "daily_df['month_cos'] = np.cos(2 * np.pi * daily_df['month'] / 12)\n",
    "\n",
    "# Weather-derived interactions\n",
    "daily_df['precipitation_binary'] = (daily_df['precipitation_sum'] > 0).astype(int)\n",
    "daily_df['temp_wind_interaction'] = daily_df['temperature_2m_mean'] * daily_df['wind_speed_10m_max']\n",
    "daily_df['precip_wind_interaction'] = daily_df['precipitation_sum'] * daily_df['wind_speed_10m_max']\n",
    "\n",
    "daily_df[\"precip_wind_u\"] = daily_df[\"precipitation_sum\"] * daily_df[\"wind_u\"]\n",
    "\n",
    "# Anomaly weather detection\n",
    "# get past 30 days of weather data\n",
    "history = weather_fg.filter(\n",
    "    (weather_fg.city == city) &\n",
    "    (weather_fg.date >= today - timedelta(days=30)) &\n",
    "    (weather_fg.date < today)\n",
    ").read()\n",
    "\n",
    "# calculate avg temp of past 30 days\n",
    "if not history.empty:\n",
    "    temp_30d_avg = history['temperature_2m_mean'].mean()\n",
    "else:\n",
    "    temp_30d_avg = daily_df['temperature_2m_mean'].iloc[0]\n",
    "daily_df[\"temperature_30d_avg\"] = temp_30d_avg.astype('float64')\n",
    "# diff between current temp and avg temp of past 30 days\n",
    "daily_df['temperature_anomaly'] = (daily_df['temperature_2m_mean'] - temp_30d_avg ).astype('float64')\n",
    "daily_df[\"temp_anomaly_wind_speed\"] = (daily_df[\"temperature_anomaly\"] * daily_df[\"wind_speed_10m_max\"]).astype('float64')\n",
    "\n",
    "daily_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c563109",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1f5008",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <span style=\"color:#ff5f27;\">‚¨ÜÔ∏è Uploading new data to the Feature Store</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9de5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert new data\n",
    "air_quality_fg.insert(aq_today_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d491b0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert new data\n",
    "weather_fg.insert(daily_df, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1666e5",
   "metadata": {},
   "source": [
    "### Add lagged data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94db1559",
   "metadata": {},
   "outputs": [],
   "source": [
    "lagged_pm25 = fs.get_or_create_feature_group(\n",
    "    name='lagged_pm25',\n",
    "    description='Lagged PM2.5 measurements',\n",
    "    version=1,\n",
    "    primary_key=['city', 'date'],\n",
    "    event_time=\"date\",\n",
    "    expectation_suite=None\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ed0bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get historical PM2.5 data (EXCLUDING today to avoid data leakage)\n",
    "# These features should be computed from past data only, not today's target value\n",
    "aq_history = air_quality_fg.filter(\n",
    "    (air_quality_fg.city == city) &\n",
    "    (air_quality_fg.date >= today - timedelta(days=30)) &\n",
    "    (air_quality_fg.date < today)  # Exclude today!\n",
    ").read().sort_values('date')\n",
    "\n",
    "windows = [1, 7, 14, 21, 30]\n",
    "\n",
    "if aq_history.empty or len(aq_history) < 2:\n",
    "    # No history yet, create empty features\n",
    "    df_feat = pd.DataFrame({\n",
    "        'city': [city],\n",
    "        'date': [today]\n",
    "    })\n",
    "    for w in windows:\n",
    "        df_feat[f'pm25_change_{w}d'] = np.nan\n",
    "        df_feat[f'pm25_std_{w}d'] = np.nan\n",
    "else:\n",
    "    # Compute features from historical data only (NO data leakage)\n",
    "    # pct_change(periods=w) looks BACKWARD: compares value to w periods ago\n",
    "    # rolling(window=w) uses the last w values\n",
    "    # We take .iloc[-1] to get the most recent historical value\n",
    "    \n",
    "    # --- PERCENT CHANGE FEATURES (from historical data) ---\n",
    "    pct_change_features = {\n",
    "        f\"pm25_change_{w}d\": aq_history[\"pm25\"].pct_change(periods=w).shift(1).iloc[-1] if len(aq_history) > w else np.nan\n",
    "        for w in windows\n",
    "    }\n",
    "    \n",
    "    # --- ROLLING STD FEATURES (from historical data) ---\n",
    "    std_features = {\n",
    "        f\"pm25_std_{w}d\": aq_history[\"pm25\"].rolling(window=w, min_periods=1).std().shift(1).iloc[-1] if len(aq_history) >= 1 else np.nan\n",
    "        for w in windows\n",
    "    }\n",
    "    \n",
    "    # --- COMBINE INTO ONE FEATURES DATAFRAME ---\n",
    "    df_feat = pd.DataFrame({**pct_change_features, **std_features}, index=[0])\n",
    "    df_feat['city'] = city\n",
    "    df_feat[\"date\"] = today\n",
    "\n",
    "lagged_pm25.insert(df_feat, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83e9e2d",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\">‚è≠Ô∏è **Next:** Part 03: Training Pipeline\n",
    " </span> \n",
    "\n",
    "In the following notebook you will read from a feature group and create training dataset within the feature store\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlfs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
