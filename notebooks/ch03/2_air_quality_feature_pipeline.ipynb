{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9e46aad",
   "metadata": {},
   "source": [
    "<span style=\"font-width:bold; font-size: 3rem; color:#333;\">- Part 02: Daily Feature Pipeline for Air Quality (aqicn.org) and weather (openmeteo)</span>\n",
    "\n",
    "## üóíÔ∏è This notebook is divided into the following sections:\n",
    "1. Download and Parse Data\n",
    "2. Feature Group Insertion\n",
    "\n",
    "\n",
    "__This notebook should be scheduled to run daily__\n",
    "\n",
    "In the book, we use a GitHub Action stored here:\n",
    "[.github/workflows/air-quality-daily.yml](https://github.com/featurestorebook/mlfs-book/blob/main/.github/workflows/air-quality-daily.yml)\n",
    "\n",
    "However, you are free to use any Python Orchestration tool to schedule this program to run daily."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe638c6",
   "metadata": {},
   "source": [
    "### <span style='color:#ff5f27'> üìù Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7de2e93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "import hopsworks\n",
    "from functions import util\n",
    "import json\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6081d1",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üåç Get the Sensor URL, Country, City, Street names from Hopsworks </span>\n",
    "\n",
    "__Update the values in the cell below.__\n",
    "\n",
    "__These should be the same values as in notebook 1 - the feature backfill notebook__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b70cd57d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection closed.\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1164445\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\"country\": \"finland\", \"city\": \"helsinki \", \"street\": \"kallio-2\", \"aqicn_url\": \"https://api.waqi.info/feed/@5717\", \"latitude\": 60.17, \"longitude\": 24.94}'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you haven't set the env variable 'HOPSWORKS_API_KEY', then uncomment the next line and enter your API key\n",
    "# os.environ[\"HOPSWORKS_API_KEY\"] = \"\"\n",
    "with open('../../data/hopsworks-api-key.txt', 'r') as file:\n",
    "    os.environ[\"HOPSWORKS_API_KEY\"] = file.read().rstrip()\n",
    "project = hopsworks.login()\n",
    "fs = project.get_feature_store() \n",
    "secrets = util.secrets_api(project.name)\n",
    "\n",
    "# This line will fail if you have not registered the AQI_API_KEY as a secret in Hopsworks\n",
    "AQI_API_KEY = secrets.get_secret(\"AQI_API_KEY\").value\n",
    "location_str = secrets.get_secret(\"SENSOR_LOCATION_JSON\").value\n",
    "location = json.loads(location_str)\n",
    "\n",
    "country=location['country']\n",
    "city=location['city']\n",
    "street=location['street']\n",
    "aqicn_url=location['aqicn_url']\n",
    "latitude=location['latitude']\n",
    "longitude=location['longitude']\n",
    "\n",
    "today = datetime.date.today()\n",
    "\n",
    "location_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2caf9289",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\"> üîÆ Get references to the Feature Groups </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66f5d7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve feature groups\n",
    "air_quality_fg = fs.get_feature_group(\n",
    "    name='air_quality',\n",
    "    version=1,\n",
    ")\n",
    "weather_fg = fs.get_feature_group(\n",
    "    name='weather',\n",
    "    version=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10b6ce8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7ffa41",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üå´ Retrieve Today's Air Quality data (PM2.5) from the AQI API</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f681af6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pm25</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>street</th>\n",
       "      <th>date</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39.0</td>\n",
       "      <td>finland</td>\n",
       "      <td>helsinki</td>\n",
       "      <td>kallio-2</td>\n",
       "      <td>2024-11-20</td>\n",
       "      <td>https://api.waqi.info/feed/@5717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pm25  country       city    street       date  \\\n",
       "0  39.0  finland  helsinki   kallio-2 2024-11-20   \n",
       "\n",
       "                                url  \n",
       "0  https://api.waqi.info/feed/@5717  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "aq_today_df = util.get_pm25(aqicn_url, country, city, street, today, AQI_API_KEY)\n",
    "aq_today_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9e24eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1 entries, 0 to 0\n",
      "Data columns (total 6 columns):\n",
      " #   Column   Non-Null Count  Dtype         \n",
      "---  ------   --------------  -----         \n",
      " 0   pm25     1 non-null      float32       \n",
      " 1   country  1 non-null      object        \n",
      " 2   city     1 non-null      object        \n",
      " 3   street   1 non-null      object        \n",
      " 4   date     1 non-null      datetime64[ns]\n",
      " 5   url      1 non-null      object        \n",
      "dtypes: datetime64[ns](1), float32(1), object(4)\n",
      "memory usage: 172.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "aq_today_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af845ab6",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üå¶ Get Weather Forecast data</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2ecb3e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinates 60.25¬∞N 25.0¬∞E\n",
      "Elevation 7.0 m asl\n",
      "Timezone None None\n",
      "Timezone difference to GMT+0 0 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>temperature_2m_mean</th>\n",
       "      <th>precipitation_sum</th>\n",
       "      <th>wind_speed_10m_max</th>\n",
       "      <th>wind_direction_10m_dominant</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-11-20</td>\n",
       "      <td>1.35</td>\n",
       "      <td>1.9</td>\n",
       "      <td>37.936893</td>\n",
       "      <td>80.716522</td>\n",
       "      <td>helsinki</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-11-21</td>\n",
       "      <td>2.90</td>\n",
       "      <td>0.1</td>\n",
       "      <td>33.114128</td>\n",
       "      <td>191.920715</td>\n",
       "      <td>helsinki</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-11-22</td>\n",
       "      <td>-1.55</td>\n",
       "      <td>0.1</td>\n",
       "      <td>16.516901</td>\n",
       "      <td>249.590027</td>\n",
       "      <td>helsinki</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-11-23</td>\n",
       "      <td>-1.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.198285</td>\n",
       "      <td>239.036301</td>\n",
       "      <td>helsinki</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-11-24</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.396570</td>\n",
       "      <td>239.036301</td>\n",
       "      <td>helsinki</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2024-11-25</td>\n",
       "      <td>5.70</td>\n",
       "      <td>0.4</td>\n",
       "      <td>33.014175</td>\n",
       "      <td>205.167831</td>\n",
       "      <td>helsinki</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2024-11-26</td>\n",
       "      <td>8.30</td>\n",
       "      <td>0.1</td>\n",
       "      <td>26.089443</td>\n",
       "      <td>230.599365</td>\n",
       "      <td>helsinki</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2024-11-27</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.290511</td>\n",
       "      <td>305.537750</td>\n",
       "      <td>helsinki</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2024-11-28</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.418526</td>\n",
       "      <td>254.744827</td>\n",
       "      <td>helsinki</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2024-11-29</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.496736</td>\n",
       "      <td>267.337036</td>\n",
       "      <td>helsinki</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  temperature_2m_mean  precipitation_sum  wind_speed_10m_max  \\\n",
       "0 2024-11-20                 1.35                1.9           37.936893   \n",
       "1 2024-11-21                 2.90                0.1           33.114128   \n",
       "2 2024-11-22                -1.55                0.1           16.516901   \n",
       "3 2024-11-23                -1.80                0.0            4.198285   \n",
       "4 2024-11-24                -0.20                0.0            8.396570   \n",
       "5 2024-11-25                 5.70                0.4           33.014175   \n",
       "6 2024-11-26                 8.30                0.1           26.089443   \n",
       "7 2024-11-27                 1.10                0.0            9.290511   \n",
       "8 2024-11-28                 2.50                0.0           16.418526   \n",
       "9 2024-11-29                 1.60                0.0           15.496736   \n",
       "\n",
       "   wind_direction_10m_dominant       city  \n",
       "0                    80.716522  helsinki   \n",
       "1                   191.920715  helsinki   \n",
       "2                   249.590027  helsinki   \n",
       "3                   239.036301  helsinki   \n",
       "4                   239.036301  helsinki   \n",
       "5                   205.167831  helsinki   \n",
       "6                   230.599365  helsinki   \n",
       "7                   305.537750  helsinki   \n",
       "8                   254.744827  helsinki   \n",
       "9                   267.337036  helsinki   "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hourly_df = util.get_hourly_weather_forecast(city, latitude, longitude)\n",
    "hourly_df = hourly_df.set_index('date')\n",
    "\n",
    "# We will only make 1 daily prediction, so we will replace the hourly forecasts with a single daily forecast\n",
    "# We only want the daily weather data, so only get weather at 12:00\n",
    "daily_df = hourly_df.between_time('11:59', '12:01')\n",
    "daily_df = daily_df.reset_index()\n",
    "daily_df['date'] = pd.to_datetime(daily_df['date']).dt.date\n",
    "daily_df['date'] = pd.to_datetime(daily_df['date'])\n",
    "daily_df['city'] = city\n",
    "daily_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c563109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 6 columns):\n",
      " #   Column                       Non-Null Count  Dtype         \n",
      "---  ------                       --------------  -----         \n",
      " 0   date                         10 non-null     datetime64[ns]\n",
      " 1   temperature_2m_mean          10 non-null     float32       \n",
      " 2   precipitation_sum            10 non-null     float32       \n",
      " 3   wind_speed_10m_max           10 non-null     float32       \n",
      " 4   wind_direction_10m_dominant  10 non-null     float32       \n",
      " 5   city                         10 non-null     object        \n",
      "dtypes: datetime64[ns](1), float32(4), object(1)\n",
      "memory usage: 448.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "daily_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1f5008",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <span style=\"color:#ff5f27;\">‚¨ÜÔ∏è Uploading new data to the Feature Store</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a9de5ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FeatureStoreException",
     "evalue": "Features are not compatible with Feature Group schema: \n - pm25_lag_1 (type: 'float') is missing from input dataframe.\n - pm25_lag_2 (type: 'float') is missing from input dataframe.\n - pm25_lag_3 (type: 'float') is missing from input dataframe.\nNote that feature (or column) names are case insensitive and spaces are automatically replaced with underscores.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFeatureStoreException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Insert new data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mair_quality_fg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43maq_today_df\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/hsfs/feature_group.py:2528\u001b[0m, in \u001b[0;36mFeatureGroup.insert\u001b[0;34m(self, features, overwrite, operation, storage, write_options, validation_options, save_code, wait)\u001b[0m\n\u001b[1;32m   2525\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwait_for_job\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m write_options:\n\u001b[1;32m   2526\u001b[0m     write_options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwait_for_job\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m wait\n\u001b[0;32m-> 2528\u001b[0m job, ge_report \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_feature_group_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2529\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2530\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_dataframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_dataframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2531\u001b[0m \u001b[43m    \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2532\u001b[0m \u001b[43m    \u001b[49m\u001b[43moperation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moperation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2533\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2534\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwrite_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwrite_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2535\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msave_report\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mvalidation_options\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2536\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m save_code \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[1;32m   2538\u001b[0m     ge_report \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m ge_report\u001b[38;5;241m.\u001b[39mingestion_result \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mINGESTED\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2539\u001b[0m ):\n\u001b[1;32m   2540\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_code_engine\u001b[38;5;241m.\u001b[39msave_code(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/hsfs/core/feature_group_engine.py:96\u001b[0m, in \u001b[0;36mFeatureGroupEngine.insert\u001b[0;34m(self, feature_group, feature_dataframe, overwrite, operation, storage, write_options, validation_options)\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_feature_group_metadata(\n\u001b[1;32m     92\u001b[0m         feature_group, dataframe_features, write_options\n\u001b[1;32m     93\u001b[0m     )\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;66;03m# else, just verify that feature group schema matches user-provided dataframe\u001b[39;00m\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_verify_schema_compatibility\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_group\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataframe_features\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m# ge validation on python and non stream feature groups on spark\u001b[39;00m\n\u001b[1;32m    101\u001b[0m ge_report \u001b[38;5;241m=\u001b[39m feature_group\u001b[38;5;241m.\u001b[39m_great_expectation_engine\u001b[38;5;241m.\u001b[39mvalidate(\n\u001b[1;32m    102\u001b[0m     feature_group\u001b[38;5;241m=\u001b[39mfeature_group,\n\u001b[1;32m    103\u001b[0m     dataframe\u001b[38;5;241m=\u001b[39mfeature_dataframe,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    106\u001b[0m     ge_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    107\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/hsfs/core/feature_group_base_engine.py:155\u001b[0m, in \u001b[0;36mFeatureGroupBaseEngine._verify_schema_compatibility\u001b[0;34m(self, feature_group_features, dataframe_features)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;66;03m# raise exception if any errors were found.\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(err) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 155\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m FeatureStoreException(\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeatures are not compatible with Feature Group schema: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m e \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m err])\n\u001b[1;32m    158\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mNote that feature (or column) names are case insensitive and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspaces are automatically replaced with underscores.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m     )\n",
      "\u001b[0;31mFeatureStoreException\u001b[0m: Features are not compatible with Feature Group schema: \n - pm25_lag_1 (type: 'float') is missing from input dataframe.\n - pm25_lag_2 (type: 'float') is missing from input dataframe.\n - pm25_lag_3 (type: 'float') is missing from input dataframe.\nNote that feature (or column) names are case insensitive and spaces are automatically replaced with underscores."
     ]
    }
   ],
   "source": [
    "# Insert new data\n",
    "air_quality_fg.insert(aq_today_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d491b0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert new data\n",
    "weather_fg.insert(daily_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83e9e2d",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\">‚è≠Ô∏è **Next:** Part 03: Training Pipeline\n",
    " </span> \n",
    "\n",
    "In the following notebook you will read from a feature group and create training dataset within the feature store\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "190ea7959a836f4799545ea0f3718ade3abee093b15861ffdc25233d6ab7050e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
