{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e64ed09c",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [7]</a>'.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615a52b0",
   "metadata": {
    "papermill": {
     "duration": 0.013399,
     "end_time": "2026-01-17T06:55:08.587213",
     "exception": false,
     "start_time": "2026-01-17T06:55:08.573814",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "test_start = \"2026-01-10 00:00\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f349d479",
   "metadata": {
    "papermill": {
     "duration": 0.005499,
     "end_time": "2026-01-17T06:55:08.599368",
     "exception": false,
     "start_time": "2026-01-17T06:55:08.593869",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Credit Card Fraud Detection - Neural Network Model\n",
    "\n",
    "This notebook trains a feedforward neural network for credit card fraud detection.\n",
    "\n",
    "**Key differences from XGBoost notebook:**\n",
    "- Uses PyTorch neural network instead of XGBoost\n",
    "- Creates Feature View v2 with MinMaxScaler and OneHotEncoder transformations\n",
    "- 3-layer feedforward network with ~30k neurons\n",
    "- L2 regularization (weight_decay) + Dropout layers\n",
    "- Class weights to handle severe class imbalance (191:1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9043b7a1",
   "metadata": {
    "papermill": {
     "duration": 0.06567,
     "end_time": "2026-01-17T06:55:08.669120",
     "exception": false,
     "start_time": "2026-01-17T06:55:08.603450",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", module=\"IPython\")\n",
    "\n",
    "root_dir = Path().absolute()\n",
    "# Strip ~/notebooks/ccfraud from PYTHON_PATH if notebook started in one of these subdirectories\n",
    "if root_dir.parts[-1:] == ('notebooks',):\n",
    "    root_dir = Path(*root_dir.parts[:-1])\n",
    "    sys.path.append(str(root_dir))\n",
    "if root_dir.parts[-1:] == ('ccfraud',):\n",
    "    root_dir = Path(*root_dir.parts[:-1])\n",
    "    sys.path.append(str(root_dir))\n",
    "root_dir = str(root_dir) \n",
    "\n",
    "print(f\"Root dir: {root_dir}\")\n",
    "\n",
    "# Set the environment variables from the file <root_dir>/.env\n",
    "from mlfs import config\n",
    "settings = config.HopsworksSettings(_env_file=f\"{root_dir}/.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c63637b",
   "metadata": {
    "papermill": {
     "duration": 2.718585,
     "end_time": "2026-01-17T06:55:11.391386",
     "exception": false,
     "start_time": "2026-01-17T06:55:08.672801",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import hopsworks\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "proj = hopsworks.login()\n",
    "fs = proj.get_feature_store()\n",
    "mr = proj.get_model_registry()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe31bc2",
   "metadata": {
    "papermill": {
     "duration": 0.009823,
     "end_time": "2026-01-17T06:55:11.407440",
     "exception": false,
     "start_time": "2026-01-17T06:55:11.397617",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Get Feature Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdd200b",
   "metadata": {
    "papermill": {
     "duration": 6.124413,
     "end_time": "2026-01-17T06:55:17.537593",
     "exception": false,
     "start_time": "2026-01-17T06:55:11.413180",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "merchant_fg = fs.get_feature_group(\"merchant_details\", version=1)\n",
    "account_fg = fs.get_feature_group(\"account_details\", version=1)\n",
    "bank_fg = fs.get_feature_group(\"bank_details\", version=1)\n",
    "card_fg = fs.get_feature_group(\"card_details\", version=1)\n",
    "cc_trans_aggs_fg = fs.get_feature_group(\"cc_trans_aggs_fg\", version=1)\n",
    "cc_trans_fg = fs.get_feature_group(\"cc_trans_fg\", version=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d567593",
   "metadata": {
    "papermill": {
     "duration": 0.019439,
     "end_time": "2026-01-17T06:55:17.563017",
     "exception": false,
     "start_time": "2026-01-17T06:55:17.543578",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Build Feature Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b432d69b",
   "metadata": {
    "papermill": {
     "duration": 0.010789,
     "end_time": "2026-01-17T06:55:17.582609",
     "exception": false,
     "start_time": "2026-01-17T06:55:17.571820",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "subtree1 = cc_trans_aggs_fg.select_except(['t_id','cc_num','account_id','bank_id','event_time'])\\\n",
    "    .join(account_fg.select(['debt_end_prev_month']), on=\"account_id\", join_type=\"inner\")\\\n",
    "    .join(bank_fg.select(['credit_rating', 'days_since_bank_cr_changed', 'country']), on=\"bank_id\", join_type=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4e6196",
   "metadata": {
    "papermill": {
     "duration": 0.006989,
     "end_time": "2026-01-17T06:55:17.593462",
     "exception": false,
     "start_time": "2026-01-17T06:55:17.586473",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "selection = cc_trans_fg.select_except(['t_id', 'cc_num', 'merchant_id', 'account_id', 'ip_address', 'ts'])\\\n",
    "    .join(merchant_fg.select_features(), prefix=\"merchant_\", on=\"merchant_id\", join_type=\"inner\")\\\n",
    "    .join(subtree1, on=\"cc_num\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44488629",
   "metadata": {
    "papermill": {
     "duration": 0.005833,
     "end_time": "2026-01-17T06:55:17.605988",
     "exception": false,
     "start_time": "2026-01-17T06:55:17.600155",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Create Feature View with Transformations\n",
    "\n",
    "Create a new feature view (version 2) with:\n",
    "- MinMaxScaler on `amount` feature\n",
    "- OneHotEncoder on categorical features: `merchant_category`, `merchant_country`, `country`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6bf0a9",
   "metadata": {
    "papermill": {
     "duration": 0.150352,
     "end_time": "2026-01-17T06:55:17.761064",
     "exception": true,
     "start_time": "2026-01-17T06:55:17.610712",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "min_max_scaler = fs.get_transformation_function(name=\"min_max_scaler\")\n",
    "one_hot_encoder = fs.get_transformation_function(name=\"one_hot_encoder\")\n",
    "\n",
    "# Define transformation functions for neural network preprocessing\n",
    "transformation_functions = [\n",
    "    min_max_scaler(\"amount\"),\n",
    "    one_hot_encoder(\"merchant_category\"),\n",
    "    one_hot_encoder(\"merchant_country\"),\n",
    "    one_hot_encoder(\"country\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6c0638",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create Feature View version 2 with transformations\n",
    "fv = fs.get_or_create_feature_view(\n",
    "    name=\"cc_fraud_fv_nn\", \n",
    "    version=1, \n",
    "    description=\"Features for credit card fraud NN model with MinMaxScaler and OneHotEncoder\",\n",
    "    query=selection,\n",
    "    labels=['is_fraud'],\n",
    "    inference_helper_columns=['prev_card_present', 'prev_ip_address', 'prev_ts'],\n",
    "    transformation_functions=transformation_functions\n",
    ")\n",
    "\n",
    "print(f\"Feature View: {fv.name}, version: {fv.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15d9088",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e821aca1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Parameters (injected by papermill)\n",
    "test_start = \"2026-01-09 00:00\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b981662",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = fv.train_test_split(test_start=test_start)\n",
    "\n",
    "print(f\"Training data: {X_train.shape[0]:,} samples, {X_train.shape[1]} features\")\n",
    "print(f\"Test data: {X_test.shape[0]:,} samples, {X_test.shape[1]} features\")\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2237d6a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Class Imbalance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfa2108",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_negative = (y_train[\"is_fraud\"] == False).sum()\n",
    "n_positive = (y_train[\"is_fraud\"] == True).sum()\n",
    "class_weight_ratio = n_negative / n_positive\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"CLASS IMBALANCE ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Negative samples (non-fraud): {n_negative:,}\")\n",
    "print(f\"Positive samples (fraud):     {n_positive:,}\")\n",
    "print(f\"Imbalance ratio:              {class_weight_ratio:.2f}:1\")\n",
    "print(f\"\\nThis will be used as pos_weight in BCEWithLogitsLoss\")\n",
    "print(f\"to give ~{class_weight_ratio:.0f}x more weight to fraud cases during training.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea2f48f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Prepare Data for PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff7c059",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Check for GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else  \"mps\" if torch.backends.mps.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Handle missing values with median imputation\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train_imputed).to(device)\n",
    "y_train_tensor = torch.FloatTensor(y_train.values.ravel()).to(device)\n",
    "X_test_tensor = torch.FloatTensor(X_test_imputed).to(device)\n",
    "y_test_tensor = torch.FloatTensor(y_test.values.ravel()).to(device)\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 256\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "input_dim = X_train_tensor.shape[1]\n",
    "print(f\"Input dimension: {input_dim}\")\n",
    "print(f\"Training batches: {len(train_loader)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b658525",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Neural Network Architecture\n",
    "\n",
    "3-layer feedforward network with ~30k neurons:\n",
    "- Layer 1: 15,000 neurons + ReLU + Dropout\n",
    "- Layer 2: 10,000 neurons + ReLU + Dropout\n",
    "- Layer 3: 5,000 neurons + ReLU + Dropout\n",
    "- Output: 1 neuron (binary classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16e0a6a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FraudDetectorNN(nn.Module):\n",
    "    def __init__(self, input_dim, dropout_rate=0.3):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_dim, 15000),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(15000, 10000),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(10000, 5000),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(5000, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "# Initialize model\n",
    "model = FraudDetectorNN(input_dim, dropout_rate=0.3).to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"NEURAL NETWORK ARCHITECTURE\")\n",
    "print(\"=\" * 80)\n",
    "print(model)\n",
    "print(f\"\\nTotal parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"\\nNeuron count: 15,000 + 10,000 + 5,000 = 30,000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325e50e3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Training Configuration\n",
    "\n",
    "- Loss: BCEWithLogitsLoss with pos_weight for class imbalance\n",
    "- Optimizer: Adam with weight_decay=0.01 (L2 regularization)\n",
    "- Learning rate: 0.001 with ReduceLROnPlateau scheduler\n",
    "- Early stopping: patience=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439349b1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loss function with class weight for imbalanced data\n",
    "pos_weight = torch.tensor([class_weight_ratio], dtype=torch.float32).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "# Optimizer with L2 regularization (weight_decay)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=5\n",
    ")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"TRAINING CONFIGURATION\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Loss function: BCEWithLogitsLoss\")\n",
    "print(f\"  - pos_weight: {class_weight_ratio:.2f} (class imbalance handling)\")\n",
    "print(f\"Optimizer: Adam\")\n",
    "print(f\"  - learning_rate: 0.001\")\n",
    "print(f\"  - weight_decay: 0.01 (L2 regularization)\")\n",
    "print(f\"Scheduler: ReduceLROnPlateau\")\n",
    "print(f\"  - patience: 5, factor: 0.5\")\n",
    "print(f\"Early stopping: patience=10\")\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "print(f\"Max epochs: 20\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4485d2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cf1f8a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "\n",
    "def evaluate_model(model, data_loader, criterion, device):\n",
    "    \"\"\"Evaluate model and return loss and PR-AUC.\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in data_loader:\n",
    "            outputs = model(X_batch).squeeze()\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            probs = torch.sigmoid(outputs).cpu().numpy()\n",
    "            all_preds.extend(probs)\n",
    "            all_labels.extend(y_batch.cpu().numpy())\n",
    "    \n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    \n",
    "    # Calculate PR-AUC\n",
    "    precision, recall, _ = precision_recall_curve(all_labels, all_preds)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    \n",
    "    return avg_loss, pr_auc\n",
    "\n",
    "# Training loop with early stopping\n",
    "num_epochs = 20\n",
    "early_stopping_patience = 10\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "best_model_state = None\n",
    "history = {'train_loss': [], 'val_loss': [], 'val_pr_auc': []}\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"TRAINING NEURAL NETWORK\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    \n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch).squeeze()\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    train_loss /= len(train_loader)\n",
    "    \n",
    "    # Validation phase\n",
    "    val_loss, val_pr_auc = evaluate_model(model, test_loader, criterion, device)\n",
    "    \n",
    "    # Update learning rate scheduler\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    # Store history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_pr_auc'].append(val_pr_auc)\n",
    "    \n",
    "    # Print progress\n",
    "    if (epoch + 1) % 5 == 0 or epoch == 0:\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        print(f\"Epoch {epoch+1:3d}/{num_epochs} | \"\n",
    "              f\"Train Loss: {train_loss:.4f} | \"\n",
    "              f\"Val Loss: {val_loss:.4f} | \"\n",
    "              f\"Val PR-AUC: {val_pr_auc:.4f} | \"\n",
    "              f\"LR: {current_lr:.6f}\")\n",
    "    \n",
    "    # Early stopping check\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model_state = model.state_dict().copy()\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= early_stopping_patience:\n",
    "            print(f\"\\nEarly stopping triggered at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "# Restore best model\n",
    "if best_model_state is not None:\n",
    "    model.load_state_dict(best_model_state)\n",
    "    print(f\"\\nRestored best model with validation loss: {best_val_loss:.4f}\")\n",
    "\n",
    "print(\"\\nTraining complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053df50f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Training History Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51209ade",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Loss plot\n",
    "axes[0].plot(history['train_loss'], label='Train Loss', color='blue')\n",
    "axes[0].plot(history['val_loss'], label='Val Loss', color='orange')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Training and Validation Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# PR-AUC plot\n",
    "axes[1].plot(history['val_pr_auc'], label='Val PR-AUC', color='green')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('PR-AUC')\n",
    "axes[1].set_title('Validation PR-AUC')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "training_history_fig = fig\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c676bc56",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf817ea6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, classification_report,\n",
    "    precision_recall_curve, auc,\n",
    "    precision_score, recall_score, f1_score\n",
    ")\n",
    "\n",
    "# Get predictions using batched inference to avoid memory issues\n",
    "model.eval()\n",
    "all_preds = []\n",
    "with torch.no_grad():\n",
    "    for X_batch, _ in test_loader:\n",
    "        batch_probs = torch.sigmoid(model(X_batch)).cpu().numpy().squeeze()\n",
    "        all_preds.extend(batch_probs)\n",
    "\n",
    "y_pred_probs = np.array(all_preds)\n",
    "y_pred = (y_pred_probs >= 0.5).astype(int)\n",
    "\n",
    "y_test_np = y_test.values.ravel()\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test_np, y_pred)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "df_cm = pd.DataFrame(cm, \n",
    "                     index=['True Non-Fraud', 'True Fraud'],\n",
    "                     columns=['Pred Non-Fraud', 'Pred Fraud'])\n",
    "\n",
    "sns.heatmap(df_cm, annot=True, fmt='d', cmap='Blues', ax=ax, cbar_kws={'label': 'Count'})\n",
    "ax.set_title('Confusion Matrix - Neural Network Fraud Detection', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('Actual', fontsize=12)\n",
    "ax.set_xlabel('Predicted', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "cm_fig = fig\n",
    "plt.show()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"CONFUSION MATRIX BREAKDOWN\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"True Negatives:  {cm[0,0]:5,} (correctly identified non-fraud)\")\n",
    "print(f\"False Positives: {cm[0,1]:5,} (non-fraud flagged as fraud)\")\n",
    "print(f\"False Negatives: {cm[1,0]:5,} (fraud missed - CRITICAL)\")\n",
    "print(f\"True Positives:  {cm[1,1]:5,} (correctly identified fraud)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b90bad",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Classification Metrics\n",
    "print(\"=\" * 80)\n",
    "print(\"CLASSIFICATION REPORT\")\n",
    "print(\"=\" * 80)\n",
    "report_dict = classification_report(y_test_np, y_pred, \n",
    "                                   target_names=['Non-Fraud', 'Fraud'],\n",
    "                                   output_dict=True)\n",
    "print(classification_report(y_test_np, y_pred, target_names=['Non-Fraud', 'Fraud']))\n",
    "\n",
    "# Calculate key metrics\n",
    "precision = precision_score(y_test_np, y_pred)\n",
    "recall = recall_score(y_test_np, y_pred)\n",
    "f1 = f1_score(y_test_np, y_pred)\n",
    "\n",
    "# PR-AUC\n",
    "precision_curve, recall_curve, _ = precision_recall_curve(y_test_np, y_pred_probs)\n",
    "pr_auc = auc(recall_curve, precision_curve)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"KEY METRICS SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"PR-AUC Score:         {pr_auc:.4f}  <- More important for imbalanced data\")\n",
    "print(f\"Precision (Fraud):    {precision:.4f}\")\n",
    "print(f\"Recall (Fraud):       {recall:.4f}\")\n",
    "print(f\"F1-Score (Fraud):     {f1:.4f}\")\n",
    "\n",
    "# Store metrics for model registry\n",
    "metrics_dict = {\n",
    "    'pr_auc': pr_auc,\n",
    "    'precision': precision,\n",
    "    'recall': recall,\n",
    "    'f1_score': f1,\n",
    "    'accuracy': report_dict['accuracy']\n",
    "}\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(f\"  - Precision: {precision*100:.1f}% of predicted frauds are actually fraudulent\")\n",
    "print(f\"  - Recall: {recall*100:.1f}% of actual frauds were detected\")\n",
    "print(f\"  - PR-AUC: {pr_auc:.4f} measures precision-recall tradeoff (higher is better)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feab8c85",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Precision-Recall Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8176aba6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "ax.plot(recall_curve, precision_curve, color='blue', lw=2, label=f'PR Curve (AUC = {pr_auc:.4f})')\n",
    "ax.fill_between(recall_curve, precision_curve, alpha=0.2, color='blue')\n",
    "ax.set_xlabel('Recall', fontsize=12)\n",
    "ax.set_ylabel('Precision', fontsize=12)\n",
    "ax.set_title('Precision-Recall Curve - Neural Network', fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='best')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_xlim([0.0, 1.0])\n",
    "ax.set_ylim([0.0, 1.05])\n",
    "\n",
    "plt.tight_layout()\n",
    "pr_curve_fig = fig\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d2141a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Save Model Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94caad21",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_dir = \"cc_fraud_nn_model\"\n",
    "images_dir = model_dir + \"/images\"\n",
    "os.makedirs(images_dir, exist_ok=True)\n",
    "\n",
    "print(f\"Model artifacts will be saved to: {model_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f74fa6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SAVING MODEL ARTIFACTS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Save PyTorch model\n",
    "model_path = model_dir + \"/cc_fraud_nn_model.pt\"\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'input_dim': input_dim,\n",
    "    'dropout_rate': 0.3,\n",
    "    'class_weight_ratio': class_weight_ratio,\n",
    "}, model_path)\n",
    "print(f\"PyTorch model saved to: {model_path}\")\n",
    "\n",
    "# Save imputer for preprocessing\n",
    "imputer_path = model_dir + \"/imputer.pkl\"\n",
    "joblib.dump(imputer, imputer_path)\n",
    "print(f\"Imputer saved to: {imputer_path}\")\n",
    "\n",
    "# Save feature column names for inference\n",
    "feature_names_path = model_dir + \"/feature_names.pkl\"\n",
    "joblib.dump(list(X_train.columns), feature_names_path)\n",
    "print(f\"Feature names saved to: {feature_names_path}\")\n",
    "\n",
    "# Save visualizations\n",
    "cm_fig.savefig(images_dir + \"/confusion_matrix.png\", dpi=100, bbox_inches='tight')\n",
    "print(f\"Confusion matrix saved to: {images_dir}/confusion_matrix.png\")\n",
    "\n",
    "training_history_fig.savefig(images_dir + \"/training_history.png\", dpi=100, bbox_inches='tight')\n",
    "print(f\"Training history saved to: {images_dir}/training_history.png\")\n",
    "\n",
    "pr_curve_fig.savefig(images_dir + \"/pr_curve.png\", dpi=100, bbox_inches='tight')\n",
    "print(f\"PR curve saved to: {images_dir}/pr_curve.png\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ALL ARTIFACTS SAVED SUCCESSFULLY\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece1ed12",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Add Predictor Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47cace3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add the predictor script to the model's directory\n",
    "predictor_script = \"ccfraud-nn-predictor.py\"\n",
    "src = Path(f\"notebooks/{predictor_script}\")\n",
    "dst_dir = Path(model_dir)\n",
    "try:\n",
    "    shutil.copy(src, dst_dir / src.name)\n",
    "except:\n",
    "    src = Path(predictor_script)\n",
    "    shutil.copy(src, dst_dir / src.name)\n",
    "    \n",
    "print(f\"Predictor script copied to: {model_dir}/{predictor_script}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595d3e3d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Register Model in Hopsworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843ff741",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"REGISTERING MODEL IN HOPSWORKS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Format metrics for model registry\n",
    "metrics_for_registry = {\n",
    "    'pr_auc': f\"{metrics_dict['pr_auc']:.4f}\",\n",
    "    'precision': f\"{metrics_dict['precision']:.4f}\",\n",
    "    'recall': f\"{metrics_dict['recall']:.4f}\",\n",
    "    'f1_score': f\"{metrics_dict['f1_score']:.4f}\",\n",
    "    'accuracy': f\"{metrics_dict['accuracy']:.4f}\",\n",
    "    'class_weight_ratio': f\"{class_weight_ratio:.2f}\",\n",
    "    'n_train_samples': str(len(y_train)),\n",
    "    'n_fraud_train': str(n_positive),\n",
    "    'imbalance_ratio': f\"{class_weight_ratio:.2f}\",\n",
    "    #'model_type': 'neural_network',\n",
    "    #'architecture': '15000-10000-5000-1',\n",
    "    'dropout_rate': '0.3',\n",
    "    'weight_decay': '0.01'\n",
    "}\n",
    "\n",
    "print(\"Model metadata:\")\n",
    "for key, value in metrics_for_registry.items():\n",
    "    print(f\"  {key:20s}: {value}\")\n",
    "\n",
    "model_name = \"cc_fraud_nn_model\"\n",
    "\n",
    "# Create model in registry\n",
    "cc_fraud_nn_model = mr.python.create_model(\n",
    "    name=model_name,\n",
    "    metrics=metrics_for_registry,\n",
    "    feature_view=fv,\n",
    "    description=\"Credit Card Fraud Detection - PyTorch Neural Network. \"\n",
    "                \"3-layer feedforward network (15k-10k-5k neurons) with dropout and L2 regularization. \"\n",
    "                f\"Trained on {len(y_train):,} samples with {n_positive} fraud cases. \"\n",
    "                f\"Uses {input_dim} features after MinMaxScaler and OneHotEncoder transformations.\"\n",
    ")\n",
    "\n",
    "# Upload model directory to registry\n",
    "cc_fraud_nn_model.save(model_dir)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"MODEL REGISTRATION COMPLETE\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Model name: {model_name}\")\n",
    "print(f\"Version: {cc_fraud_nn_model.version}\")\n",
    "print(f\"Feature View: cc_fraud_fv v2 (with MinMaxScaler + OneHotEncoder)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c877fd8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Optional: Deploy Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42e4822",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Deploy the model (uncomment to run)\n",
    "ms = proj.get_model_serving()\n",
    "env_api = proj.get_environment_api()\n",
    "ds_api = proj.get_dataset_api()\n",
    "\n",
    "best_model = mr.get_best_model(name=model_name, metric=\"f1_score\", direction=\"max\")\n",
    "\n",
    "env_name = \"cloned-torch-inference-pipeline\"\n",
    "\n",
    "if not env_api.get_environment(env_name):\n",
    "    env = env_api.create_environment(env_name, base_environment_name=\"torch-inference-pipeline\")\n",
    "    requirements_path = ds_api.upload(f\"{root_dir}/ccfraud/requirements.txt\", \"Resources\", overwrite=True)\n",
    "    env.install_requirements(requirements_path, await_installation=True)\n",
    "\n",
    "# If the model I trained is better than the existing model deployment, replace it with this one\n",
    "if best_model.version == cc_fraud_nn_model.version:\n",
    "    print(f\"This is the best model version at: {best_model.version_path}\")\n",
    "    predictor_path = os.path.join(best_model.version_path, f\"Files/{predictor_script}\")\n",
    "    deployment_name = \"ccfraudnn\"\n",
    "    try:\n",
    "        deployment = ms.get_deployment(deployment_name)\n",
    "        deployment.delete(force=True)\n",
    "        print(f\"Deleted deployment {deployment_name}\")\n",
    "    except:\n",
    "        print(\"Deployment not running\")\n",
    "    deployment = best_model.deploy(\n",
    "        name=deployment_name, \n",
    "        script_file=predictor_path, \n",
    "        environment=env_name,\n",
    "        resources={\"num_instances\": 1, \"requests\": {\"cores\": 1, \"memory\": 1024}, \"limits\": {\"cores\": 4, \"memory\": 1024*3}},\n",
    "    )\n",
    "    deployment.start(await_running=180)\n",
    "    deployment_state = deployment.get_state().describe()\n",
    "else:\n",
    "    print(\"Not deploying this model, as its performance is worse than the existing deployment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d42d8c1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"NOTEBOOK COMPLETE\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nSummary:\")\n",
    "print(f\"  - Feature View: cc_fraud_fv v2 (with transformations)\")\n",
    "print(f\"  - Model: 3-layer Neural Network ({total_params:,} parameters)\")\n",
    "print(f\"  - Architecture: 15,000 -> 10,000 -> 5,000 -> 1 neurons\")\n",
    "print(f\"  - Regularization: L2 (weight_decay=0.01) + Dropout (0.3)\")\n",
    "print(f\"  - Class imbalance: pos_weight={class_weight_ratio:.2f}\")\n",
    "print(f\"\\nMetrics:\")\n",
    "print(f\"  - PR-AUC: {pr_auc:.4f}\")\n",
    "print(f\"  - Precision: {precision:.4f}\")\n",
    "print(f\"  - Recall: {recall:.4f}\")\n",
    "print(f\"  - F1-Score: {f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 10.321564,
   "end_time": "2026-01-17T06:55:18.182317",
   "environment_variables": {},
   "exception": true,
   "input_path": "notebooks/4b-training-nn-fraud-model.ipynb",
   "output_path": "notebooks/4b-training-nn-fraud-model.ipynb",
   "parameters": {
    "test_start": "2026-01-10 00:00"
   },
   "start_time": "2026-01-17T06:55:07.860753",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
