{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "802ec6a1-b608-40a5-931f-5e7dfb2d7046",
   "metadata": {},
   "source": [
    "# Step 1: Real-Time Feature Computation\n",
    "\n",
    "This notebook is part of a demo showcasing a real-time fraud detection pipeline, utilizing Feldera for feature computation and Hopsworks as the feature store.\n",
    "\n",
    "![Real-time feature engineering pipeline using Feldera and Hosworks](./architecture.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bc94df-de0a-4faa-93b1-c98cf2948b9e",
   "metadata": {},
   "source": [
    "## Step 1.1. Create Hopsworks feature groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "736d8b3f-d661-4413-ab5b-9fa8e07f0162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root dir: /home/jdowling/Projects/mlfs-book\n",
      "HopsworksSettings initialized!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "root_dir = Path().absolute()\n",
    "# Strip ~/notebooks/ccfraud from PYTHON_PATH if notebook started in one of these subdirectories\n",
    "if root_dir.parts[-1:] == ('notebooks',):\n",
    "    root_dir = Path(*root_dir.parts[:-1])\n",
    "    sys.path.append(str(root_dir))\n",
    "if root_dir.parts[-1:] == ('ccfraud',):\n",
    "    root_dir = Path(*root_dir.parts[:-1])\n",
    "    sys.path.append(str(root_dir))\n",
    "root_dir = str(root_dir) \n",
    "\n",
    "print(f\"Root dir: {root_dir}\")\n",
    "\n",
    "# Set the environment variables from the file <root_dir>/.env\n",
    "from mlfs import config\n",
    "settings = config.HopsworksSettings(_env_file=f\"{root_dir}/.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9580f0-df38-4c19-9981-127b0c1179e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2037b50-de20-43f4-b8cc-c67196f920f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-28 08:49:20,705 INFO: Initializing external client\n",
      "2025-12-28 08:49:20,706 INFO: Base URL: https://c.app.hopsworks.ai:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "UserWarning: The installed hopsworks client version 4.4.3 may not be compatible with the connected Hopsworks backend version 4.2.2. \n",
      "To ensure compatibility please install the latest bug fix release matching the minor version of your backend (4.2) by running 'pip install hopsworks==4.2.*'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-28 08:49:21,107 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/398\n"
     ]
    }
   ],
   "source": [
    "import hopsworks\n",
    "import hsfs\n",
    "from hsfs.feature import Feature\n",
    "import json\n",
    "import datetime\n",
    "from feldera import FelderaClient, PipelineBuilder\n",
    "\n",
    "client = FelderaClient(\"http://localhost:8080\")\n",
    "\n",
    "project = hopsworks.login()\n",
    "hostname = project.get_url().removeprefix(\"https://\").split(\":\", 1)[0]\n",
    "\n",
    "kafka_api = project.get_kafka_api()\n",
    "\n",
    "fs = project.get_feature_store()\n",
    "\n",
    "name = \"cc_trans_aggs_fg\"\n",
    "kafka_topic = f\"{project.name}_onlinefs\"\n",
    "aggs_topic=f\"{project.name}_{name}_onlinefs\"\n",
    "\n",
    "cc_trans_fg = fs.get_feature_group(name=\"credit_card_transactions\", version=1)\n",
    "card_details_fg = fs.get_feature_group(name=\"card_details\", version=1)\n",
    "\n",
    "\n",
    "# WINDOWED - frequency of transactions and other metrics in the span of a few hours, modeled as hopping window aggregates.\n",
    "windowed_fg = fs.get_or_create_feature_group(\n",
    "    name=name,\n",
    "    primary_key=[\"cc_num\"],\n",
    "    online_enabled=True,\n",
    "    version=1,\n",
    "    event_time=\"event_time\",\n",
    "    # topic_name=aggs_topic,    \n",
    "    stream=True,\n",
    "    features=[        \n",
    "        Feature(\"cc_num\", type=\"string\"),\n",
    "        Feature(\"account_id\", type=\"string\"),\n",
    "        Feature(\"bank_id\", type=\"string\"),\n",
    "        Feature(\"num_trans_last_10_mins\", type=\"bigint\"),\n",
    "        Feature(\"sum_trans_last_10_mins\", type=\"double\"),\n",
    "        Feature(\"num_trans_last_hour\", type=\"bigint\"),\n",
    "        Feature(\"sum_trans_last_hour\", type=\"double\"),\n",
    "        Feature(\"num_trans_last_day\", type=\"bigint\"),\n",
    "        Feature(\"sum_trans_last_day\", type=\"double\"),\n",
    "        Feature(\"num_trans_last_week\", type=\"bigint\"),\n",
    "        Feature(\"sum_trans_last_week\", type=\"double\"),\n",
    "        Feature(\"prev_card_present\", type=\"boolean\"),\n",
    "        Feature(\"prev_ip_transaction\", type=\"string\"),\n",
    "        Feature(\"prev_ts_transaction\", type=\"timestamp\"),\n",
    "        Feature(\"event_time\", type=\"timestamp\"),\n",
    "    ],    \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4426b45a-51c9-49eb-abfc-10d29aff370b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata operation error: (url: https://c.app.hopsworks.ai/hopsworks-api/api/project/398/featurestores/335/featuregroups). Server response: \n",
      "HTTP code: 400, HTTP reason: Bad Request, body: b'{\"errorCode\":270089,\"usrMsg\":\"project: dowlingj, featurestoreId: 335\",\"errorMsg\":\"The feature group you are trying to create does already exist.\"}', error code: 270089, error msg: The feature group you are trying to create does already exist., user msg: project: dowlingj, featurestoreId: 335\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    windowed_fg.save()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "653325c0-7645-4670-b08f-b9ce0531e2dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dowlingj_onlinefs\n"
     ]
    }
   ],
   "source": [
    "kafka_api = project.get_kafka_api()\n",
    "\n",
    "kafka_topics = kafka_api.get_topics()\n",
    "for topic in kafka_topics:\n",
    "    print(f\"{topic.name}\")\n",
    "    if topic.name == \"dowlingj_credit_card_transactions_onlinefs\" or topic.name==\"dowlingj_cc_trans_aggs_fg\":\n",
    "        topic.delete()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38444377-ffc4-4746-89d5-1ced6fdc7053",
   "metadata": {},
   "source": [
    "## Load certs in Feldera Container\n",
    "\n",
    "Feldera expects the certs to be in /tmp/HOPSWORKS_HOST/HOPSWORKS_PROJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40fc35be-7e0a-4ea2-a554-0816eac55cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "container_id is 04cbe135a6ee\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['docker', 'exec', '04cbe135a6ee', 'bash', '-c', 'rm -f /tmp/c.app.hopsworks.ai && ln -s /opt/c.app.hopsworks.ai/c.app.hopsworks.ai /tmp/c.app.hopsworks.ai'], returncode=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# Get container ID\n",
    "container_id = subprocess.check_output(\n",
    "    [\"docker\", \"ps\", \"--filter\", \"ancestor=ghcr.io/feldera/pipeline-manager:latest\", \"-q\"],\n",
    "    text=True\n",
    ").strip()\n",
    "\n",
    "print(f\"container_id is {container_id}\")\n",
    "# Run the command inside the container\n",
    "subprocess.run([\n",
    "    \"docker\", \"exec\", container_id,\n",
    "    \"bash\", \"-c\",\n",
    "    f\"rm -f /tmp/{hostname} && ln -s /opt/{hostname}/{hostname} /tmp/{hostname}\"\n",
    "])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "44b4322a-1cea-4fd6-8ca9-02f0126456f6",
   "metadata": {},
   "source": [
    "## Step 1.2. Create Feldera pipeline\n",
    "\n",
    "We build a Feldera pipeline to transform raw transaction and profile data into features. In Feldera, feature groups are modeled as SQL views. Thus, we create a SQL program with two input tables (TRANSACTIONS and PROFILES), and two output views, one for each feature group.\n",
    "\n",
    "![Feldera pipeline](./feldera_pipeline.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fb8e951-69e3-4ddc-8e61-7c8ddbba3be1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create SQL program parameterized by source and sink connnector configurations.\n",
    "\n",
    "\n",
    "\n",
    "def build_sql(\n",
    "    transaction_source_config: str, card_details_source_config: str, fs_sink_config: str\n",
    ") -> str:\n",
    "    return f\"\"\"\n",
    "\n",
    "    CREATE TABLE credit_card_transactions (\n",
    "        t_id BIGINT,\n",
    "        merchant_id VARCHAR,\n",
    "        ts TIMESTAMP,\n",
    "        cc_num VARCHAR,\n",
    "        amount DOUBLE,\n",
    "        ip_address VARCHAR,\n",
    "        card_present BOOLEAN\n",
    "    ) WITH (\n",
    "        'connectors' = '[{transaction_source_config}]'\n",
    "    );\n",
    "\n",
    "    CREATE MATERIALIZED VIEW rolling_aggregates AS\n",
    "    SELECT\n",
    "        t.cc_num, \n",
    "        t.ts AS event_time, \n",
    "        t.ip_address,\n",
    "        t.card_present,\n",
    "        SUM(COALESCE(amount, 0)) OVER window_10_minute AS sum_trans_last_10_mins,\n",
    "        COUNT(amount) OVER window_10_minute AS num_trans_last_10_mins,\n",
    "        SUM(COALESCE(amount, 0)) OVER window_1_hour AS sum_trans_last_hour,\n",
    "        COUNT(amount) OVER window_1_hour AS num_trans_last_hour,\n",
    "        SUM(COALESCE(amount, 0)) OVER window_1_day AS sum_trans_last_day,\n",
    "        COUNT(amount) OVER window_1_day AS num_trans_last_day,\n",
    "        SUM(COALESCE(amount, 0)) OVER window_7_day AS sum_trans_last_week,\n",
    "        COUNT(amount) OVER window_7_day AS num_trans_last_week\n",
    "    FROM\n",
    "         credit_card_transactions AS t\n",
    "    WINDOW\n",
    "        window_10_minute AS (\n",
    "            PARTITION BY cc_num\n",
    "            ORDER BY ts\n",
    "            RANGE BETWEEN INTERVAL '10' MINUTE PRECEDING AND CURRENT ROW\n",
    "        ),\n",
    "        window_1_hour AS (\n",
    "            PARTITION BY cc_num\n",
    "            ORDER BY ts\n",
    "            RANGE BETWEEN INTERVAL '1' HOUR PRECEDING AND CURRENT ROW\n",
    "        ),\n",
    "        window_1_day AS (\n",
    "            PARTITION BY cc_num\n",
    "            ORDER BY ts\n",
    "            RANGE BETWEEN INTERVAL '1' DAY PRECEDING AND CURRENT ROW\n",
    "        ),\n",
    "        window_7_day AS (\n",
    "            PARTITION BY cc_num\n",
    "            ORDER BY ts\n",
    "            RANGE BETWEEN INTERVAL '7' DAY PRECEDING AND CURRENT ROW\n",
    "        )\n",
    "    ;\n",
    "    \n",
    "    CREATE TABLE card_details (\n",
    "        cc_num VARCHAR NOT NULL,\n",
    "        account_id VARCHAR NOT NULL,\n",
    "        bank_id VARCHAR NOT NULL,\n",
    "        cc_expiry_date TIMESTAMP,\n",
    "        issue_date TIMESTAMP,\n",
    "        card_type VARCHAR,\n",
    "        status VARCHAR,\n",
    "        last_modified TIMESTAMP\n",
    "    ) WITH (\n",
    "        'connectors' = '[{card_details_source_config}]'\n",
    "    );\n",
    "\n",
    "\n",
    "    CREATE MATERIALIZED VIEW cc_trans_card AS\n",
    "    SELECT\n",
    "        ra.*,\n",
    "        cd.account_id,\n",
    "        cd.bank_id\n",
    "    FROM rolling_aggregates AS ra\n",
    "    LEFT ASOF JOIN card_details AS cd\n",
    "        MATCH_CONDITION (ra.event_time >= cd.last_modified)\n",
    "        ON ra.cc_num = cd.cc_num\n",
    "    ;\n",
    "    \n",
    "    CREATE MATERIALIZED VIEW lagged_trans AS\n",
    "    SELECT\n",
    "        ctc.*,\n",
    "        LAG(event_time) OVER \n",
    "          (PARTITION BY cc_num ORDER BY event_time ASC) AS prev_ts_transaction,\n",
    "        LAG(ip_address) OVER \n",
    "          (PARTITION BY cc_num ORDER BY ip_address ASC) AS prev_ip_transaction,\n",
    "        LAG(card_present) OVER \n",
    "          (PARTITION BY cc_num ORDER BY card_present ASC) AS prev_card_present\n",
    "    FROM cc_trans_card AS ctc;\n",
    "        \n",
    "    CREATE VIEW cc_trans_aggs_fg\n",
    "    WITH (\n",
    "        'connectors' = '[{fs_sink_config}]'\n",
    "    ) \n",
    "    AS \n",
    "        SELECT\n",
    "            cc_num,\n",
    "            event_time,\n",
    "            account_id,\n",
    "            bank_id,\n",
    "            sum_trans_last_10_mins,\n",
    "            num_trans_last_10_mins,\n",
    "            sum_trans_last_hour,\n",
    "            num_trans_last_hour,\n",
    "            sum_trans_last_day,\n",
    "            num_trans_last_day,\n",
    "            sum_trans_last_week,\n",
    "            num_trans_last_week,\n",
    "            prev_ts_transaction, \n",
    "            prev_ip_transaction,\n",
    "            prev_card_present\n",
    "        FROM lagged_trans\n",
    "    ;\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d9d834-6e5b-434e-b158-e2e6888e7839",
   "metadata": {},
   "source": [
    "### Connect Kafka sources and sinks\n",
    "\n",
    "We use the Kafka topic created during the data prep step as the input for the TRANSACTIONS table. The output views are also connected to the Hopsworks feature store via Kafka. Hopsworks ingests data from Kafka using the Avro format, so we configure Feldera Kafka connectors with Avro schemas generated by Hopsworks for each feature group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b5663a3-e5b3-46d6-9143-a4165ee31993",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_consumer_kafka_config(kafka_config: dict, fg):\n",
    "    return kafka_config | {\n",
    "        \"topic\": fg._online_topic_name,\n",
    "        \"start_from\": \"earliest\",        \n",
    "    }\n",
    "    \n",
    "\n",
    "def create_producer_kafka_config(kafka_config: dict, fg, project):\n",
    "    return kafka_config | {\n",
    "        # \"topic\": f\"{project.name}_onlinefs\",\n",
    "        \"topic\": fg._online_topic_name,\n",
    "        \"auto.offset.reset\": \"earliest\",\n",
    "        \"headers\": [\n",
    "            {\n",
    "                \"key\": \"projectId\",\n",
    "                \"value\": str(project.id),\n",
    "            },\n",
    "            {\n",
    "                \"key\": \"featureGroupId\",\n",
    "                \"value\": str(fg.id),\n",
    "            },\n",
    "            {\n",
    "                \"key\": \"subjectId\",\n",
    "                \"value\": str(fg.subject[\"id\"]),\n",
    "            },\n",
    "        ],\n",
    "    }\n",
    "\n",
    "kafka_config = kafka_api.get_default_config()\n",
    "\n",
    "fs_sink_config = json.dumps(\n",
    "    {\n",
    "        \"transport\": {\n",
    "            \"name\": \"kafka_output\",\n",
    "            \"config\": create_producer_kafka_config(kafka_config, windowed_fg, project),\n",
    "        },\n",
    "        \"format\": {\n",
    "            \"name\": \"avro\",\n",
    "            \"config\": {\"schema\": windowed_fg.avro_schema, \"skip_schema_id\": True},\n",
    "        },\n",
    "    }\n",
    ")\n",
    "\n",
    "transaction_source_config = json.dumps(\n",
    "    {\n",
    "        \"transport\": {\n",
    "            \"name\": \"kafka_input\",\n",
    "            \"config\": create_consumer_kafka_config(kafka_config, cc_trans_fg),\n",
    "        },\n",
    "        \"format\": {\n",
    "            \"name\": \"avro\",\n",
    "            \"config\": {\"schema\": cc_trans_fg.avro_schema, \"skip_schema_id\": True},\n",
    "        },\n",
    "    }\n",
    ")\n",
    "\n",
    "card_details_source_config = json.dumps(\n",
    "    {\n",
    "        \"transport\": {\n",
    "            \"name\": \"kafka_input\",\n",
    "            \"config\": create_consumer_kafka_config(kafka_config, card_details_fg),\n",
    "        },\n",
    "        \"format\": {\n",
    "            \"name\": \"avro\",\n",
    "            \"config\": {\"schema\": card_details_fg.avro_schema, \"skip_schema_id\": True},\n",
    "        },\n",
    "    }\n",
    ")\n",
    "\n",
    "sql = build_sql(transaction_source_config, card_details_source_config, fs_sink_config)\n",
    "pipeline = PipelineBuilder(client, name=\"hopsworks_kafka\", sql=sql).create_or_replace()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d661e44-fd7a-4627-a6c5-ac48198611a8",
   "metadata": {},
   "source": [
    "## Step 1.3. Run the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fece25e-7c9e-4967-bc9b-489af045e999",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown value 'Stopped' for enum PipelineStatus",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Start the Feldera pipeline.\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Read profile data from the feature store and write it to the `PROFILE` table.\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/mlfs-book/ccfraud/.venv/lib/python3.11/site-packages/feldera/pipeline.py:357\u001b[39m, in \u001b[36mPipeline.start\u001b[39m\u001b[34m(self, timeout_s)\u001b[39m\n\u001b[32m    341\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstart\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout_s: Optional[\u001b[38;5;28mfloat\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    342\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    343\u001b[39m \u001b[33;03m    .. _start:\u001b[39;00m\n\u001b[32m    344\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    354\u001b[39m \u001b[33;03m    :raises RuntimeError: If the pipeline is not in SHUTDOWN state.\u001b[39;00m\n\u001b[32m    355\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m357\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__failed_check\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstart\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    358\u001b[39m     status = \u001b[38;5;28mself\u001b[39m.status()\n\u001b[32m    359\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != PipelineStatus.SHUTDOWN:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/mlfs-book/ccfraud/.venv/lib/python3.11/site-packages/feldera/pipeline.py:329\u001b[39m, in \u001b[36mPipeline.__failed_check\u001b[39m\u001b[34m(self, next)\u001b[39m\n\u001b[32m    324\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__failed_check\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mnext\u001b[39m):\n\u001b[32m    325\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    326\u001b[39m \u001b[33;03m    Checks if the pipeline is in FAILED state and raises an error if it is.\u001b[39;00m\n\u001b[32m    327\u001b[39m \u001b[33;03m    :meta private:\u001b[39;00m\n\u001b[32m    328\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m329\u001b[39m     status = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstatus\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    330\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status == PipelineStatus.FAILED:\n\u001b[32m    331\u001b[39m         deployment_error = \u001b[38;5;28mself\u001b[39m.client.get_pipeline(\u001b[38;5;28mself\u001b[39m.name).deployment_error\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/mlfs-book/ccfraud/.venv/lib/python3.11/site-packages/feldera/pipeline.py:64\u001b[39m, in \u001b[36mPipeline.status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     63\u001b[39m     \u001b[38;5;28mself\u001b[39m.refresh()\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPipelineStatus\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdeployment_status\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m FelderaAPIError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m     67\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m err.status_code == \u001b[32m404\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/mlfs-book/ccfraud/.venv/lib/python3.11/site-packages/feldera/enums.py:190\u001b[39m, in \u001b[36mPipelineStatus.from_str\u001b[39m\u001b[34m(value)\u001b[39m\n\u001b[32m    188\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m member.name.lower() == value.lower():\n\u001b[32m    189\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m member\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnknown value \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m for enum \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mPipelineStatus.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: Unknown value 'Stopped' for enum PipelineStatus"
     ]
    }
   ],
   "source": [
    "# Start the Feldera pipeline.\n",
    "# Read profile data from the feature store and write it to the `PROFILE` table.\n",
    "pipeline.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe20fe5-4d25-4b5b-be22-c465661727b7",
   "metadata": {},
   "source": [
    "## Schedule periodic materialization to the offline store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d13bc89-1b47-4e07-bec4-2eb5b3685d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: cc_trans_aggs_fg_1_offline_fg_materialization\n"
     ]
    },
    {
     "ename": "RestAPIError",
     "evalue": "Metadata operation error: (url: https://c.app.hopsworks.ai/hopsworks-api/api/project/398/jobs/cc_trans_aggs_fg_1_offline_fg_materialization/executions). Server response: \nHTTP code: 400, HTTP reason: Bad Request, body: b'{\"errorCode\":130000,\"usrMsg\":\"Failed to start job:cc_trans_aggs_fg_1_offline_fg_materialization\",\"devMsg\":\"Operation: [get]  for kind: [ServiceAccount]  with name: [spark-launcher]  in namespace: [dowlingj]  failed.\",\"errorMsg\":\"An error occurred while trying to start this job. Check the job logs for details\"}', error code: 130000, error msg: An error occurred while trying to start this job. Check the job logs for details, user msg: Failed to start job:cc_trans_aggs_fg_1_offline_fg_materialization",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRestAPIError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtime\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# wait 900s until data has been written before materializing to the offline store\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# time.sleep(900)\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# pipeline.stop(force=True)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mwindowed_fg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmaterialization_job\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# windowed_fg.materialization_job.schedule(\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m#     cron_expression=\"0 0 3 * * ? *\",\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m#     start_time=datetime.datetime.now(tz=datetime.timezone.utc),\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# )\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/mlfs-book/ccfraud/.venv/lib/python3.11/site-packages/hopsworks_common/usage.py:246\u001b[39m, in \u001b[36mmethod_logger.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    244\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    245\u001b[39m     exception = e\n\u001b[32m--> \u001b[39m\u001b[32m246\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    247\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    248\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/mlfs-book/ccfraud/.venv/lib/python3.11/site-packages/hopsworks_common/usage.py:242\u001b[39m, in \u001b[36mmethod_logger.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    239\u001b[39m exception = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    240\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# Call the original method\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m242\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    243\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[32m    244\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/mlfs-book/ccfraud/.venv/lib/python3.11/site-packages/hopsworks_common/job.py:181\u001b[39m, in \u001b[36mJob.run\u001b[39m\u001b[34m(self, args, await_termination)\u001b[39m\n\u001b[32m    179\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    180\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLaunching job: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m181\u001b[39m execution = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execution_api\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_start\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    183\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mJob started successfully, you can follow the progress at \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mexecution.get_url()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    184\u001b[39m )\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m await_termination:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/mlfs-book/ccfraud/.venv/lib/python3.11/site-packages/hopsworks_common/core/execution_api.py:26\u001b[39m, in \u001b[36mExecutionApi._start\u001b[39m\u001b[34m(self, job, args)\u001b[39m\n\u001b[32m     22\u001b[39m _client = client.get_instance()\n\u001b[32m     23\u001b[39m path_params = [\u001b[33m\"\u001b[39m\u001b[33mproject\u001b[39m\u001b[33m\"\u001b[39m, _client._project_id, \u001b[33m\"\u001b[39m\u001b[33mjobs\u001b[39m\u001b[33m\"\u001b[39m, job.name, \u001b[33m\"\u001b[39m\u001b[33mexecutions\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m execution.Execution.from_response_json(\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m     \u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPOST\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m, job\n\u001b[32m     27\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/mlfs-book/ccfraud/.venv/lib/python3.11/site-packages/hopsworks_common/decorators.py:48\u001b[39m, in \u001b[36mconnected.<locals>.if_connected\u001b[39m\u001b[34m(inst, *args, **kwargs)\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inst._connected:\n\u001b[32m     47\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m NoHopsworksConnectionError\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/mlfs-book/ccfraud/.venv/lib/python3.11/site-packages/hopsworks_common/client/base.py:186\u001b[39m, in \u001b[36mClient._send_request\u001b[39m\u001b[34m(self, method, path_params, query_params, headers, data, stream, files, with_base_path_params)\u001b[39m\n\u001b[32m    181\u001b[39m     response = \u001b[38;5;28mself\u001b[39m._retry_token_expired(\n\u001b[32m    182\u001b[39m         request, stream, \u001b[38;5;28mself\u001b[39m.TOKEN_EXPIRED_RETRY_INTERVAL, \u001b[32m1\u001b[39m\n\u001b[32m    183\u001b[39m     )\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response.status_code // \u001b[32m100\u001b[39m != \u001b[32m2\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions.RestAPIError(url, response)\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[32m    189\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[31mRestAPIError\u001b[39m: Metadata operation error: (url: https://c.app.hopsworks.ai/hopsworks-api/api/project/398/jobs/cc_trans_aggs_fg_1_offline_fg_materialization/executions). Server response: \nHTTP code: 400, HTTP reason: Bad Request, body: b'{\"errorCode\":130000,\"usrMsg\":\"Failed to start job:cc_trans_aggs_fg_1_offline_fg_materialization\",\"devMsg\":\"Operation: [get]  for kind: [ServiceAccount]  with name: [spark-launcher]  in namespace: [dowlingj]  failed.\",\"errorMsg\":\"An error occurred while trying to start this job. Check the job logs for details\"}', error code: 130000, error msg: An error occurred while trying to start this job. Check the job logs for details, user msg: Failed to start job:cc_trans_aggs_fg_1_offline_fg_materialization"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# wait 900s until data has been written before materializing to the offline store\n",
    "# time.sleep(900)\n",
    "# pipeline.stop(force=True)\n",
    "windowed_fg.materialization_job.run()\n",
    "\n",
    "# windowed_fg.materialization_job.schedule(\n",
    "#     cron_expression=\"0 0 3 * * ? *\",\n",
    "#     start_time=datetime.datetime.now(tz=datetime.timezone.utc),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fe08d3-169c-40bd-9809-7d7c4d575e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write_options={\n",
    "#     \"wait_for_online_ingestion\":\"false\",\n",
    "#     \"wait_for_job\":\"false\",\n",
    "#     \"hoodie.streamer.kafka.source.maxEvents\":\"50000000\",\n",
    "# \"hoodie.deltastreamer.source.kafka.auto.offset.reset\" : \"earliest\",\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8369a7-c885-43b5-a9de-56641a1881f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import hopsworks\n",
    "\n",
    "# project = hopsworks.login()\n",
    "# kafka_api = project.get_kafka_api()\n",
    "# for topic_name in [topic.name for topic in kafka_api.get_topics()]:\n",
    "#     print(f\"Found topic: {topic_name}\")\n",
    "# topic = kafka_api.get_topic(\"dowlingj_cc_trans_aggs_fg\")\n",
    "# topic.delete()    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
