{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b67cf63-2834-4eaf-9cd7-022e18297cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root dir: /home/jdowling/Projects/mlfs-book\n",
      "HopsworksSettings initialized!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", module=\"IPython\")\n",
    "\n",
    "root_dir = Path().absolute()\n",
    "# Strip ~/notebooks/ccfraud from PYTHON_PATH if notebook started in one of these subdirectories\n",
    "if root_dir.parts[-1:] == ('notebooks',):\n",
    "    root_dir = Path(*root_dir.parts[:-1])\n",
    "    sys.path.append(str(root_dir))\n",
    "if root_dir.parts[-1:] == ('ccfraud',):\n",
    "    root_dir = Path(*root_dir.parts[:-1])\n",
    "    sys.path.append(str(root_dir))\n",
    "root_dir = str(root_dir) \n",
    "\n",
    "print(f\"Root dir: {root_dir}\")\n",
    "\n",
    "# Set the environment variables from the file <root_dir>/.env\n",
    "from mlfs import config\n",
    "settings = config.HopsworksSettings(_env_file=f\"{root_dir}/.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "448d85db-9048-49aa-91cc-b8d68efcc613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-05 12:20:05,059 INFO: Initializing external client\n",
      "2026-01-05 12:20:05,061 INFO: Base URL: https://eu-west.cloud.hopsworks.ai:443\n",
      "2026-01-05 12:20:05,863 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://eu-west.cloud.hopsworks.ai:443/p/120\n"
     ]
    }
   ],
   "source": [
    "import hopsworks\n",
    "import pandas as pd\n",
    "\n",
    "proj = hopsworks.login()\n",
    "fs = proj.get_feature_store()\n",
    "mr = proj.get_model_registry()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7ae47e2-2ebb-46c0-809b-e375a1bc5a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "merchant_fg = fs.get_feature_group(\"merchant_details\", version=1)\n",
    "account_fg = fs.get_feature_group(\"account_details\", version=1)\n",
    "bank_fg = fs.get_feature_group(\"bank_details\", version=1)\n",
    "card_fg = fs.get_feature_group(\"card_details\", version=1)\n",
    "cc_trans_aggs_fg = fs.get_feature_group(\"cc_trans_aggs_fg\", version=1)\n",
    "cc_trans_fg = fs.get_feature_group(\"cc_trans_fg\", version=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b553e6b-b030-43a2-92bb-d4fea9d84345",
   "metadata": {},
   "outputs": [],
   "source": [
    "subtree1 = cc_trans_aggs_fg.select_all()\\\n",
    "    .join(account_fg.select(['debt_end_prev_month']), on=\"account_id\", join_type=\"inner\")\\\n",
    "    .join(bank_fg.select(['credit_rating', 'days_since_bank_cr_changed', 'country']), on=\"bank_id\", join_type=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a36037f-45ba-467d-bacb-2e35692d4294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = subtree1.read()\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "105ecb21-de06-447d-bc80-3f62da07e04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-05 12:20:11,006 INFO: Using ['category', 'country', 'cnt_chrgeback_prev_day', 'cnt_chrgeback_prev_week', 'cnt_chrgeback_prev_month'] from feature group `merchant_details` as features for the query. To include primary key and event time use `select_all`.\n"
     ]
    }
   ],
   "source": [
    "selection = cc_trans_fg.select_except(['t_id', 'cc_num', 'merchant_id', 'account_id', 'ip_address', 'ts'])\\\n",
    "    .join(merchant_fg.select_features(), prefix=\"merchant_\", on=\"merchant_id\")\\\n",
    "    .join(subtree1, on=\"cc_num\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "567c915a-8d57-40b3-9772-20c47a8fdad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = selection.read()\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b762e14-1055-4868-aeed-e4e2a63397c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fv = fs.get_or_create_feature_view(name=\"cc_fraud_fv\", \n",
    "                                   version=1, \n",
    "                                   description=\"features for a credit card fraud prediction model\",\n",
    "                                   query=selection,\n",
    "                                   labels=['is_fraud']\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6909b96-6934-446d-98de-74585c87ba4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_start=\"2025-09-30 00:00\"\n",
    "X_train, X_test, y_train, y_test = fv.train_test_split(test_start=test_start)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9996a8b1-7f66-4e25-96fd-d483dbd2b014",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bf34dc-9bf5-43fd-83c2-f21b3e0d85de",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rwg6jagh31j",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Type Analysis\n",
    "# Inspect feature types and missing values to understand preprocessing needs\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"FEATURE DATA TYPES\")\n",
    "print(\"=\" * 80)\n",
    "print(X_train.dtypes)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"MISSING VALUES SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "missing_counts = X_train.isnull().sum()\n",
    "missing_pct = (X_train.isnull().sum() / len(X_train) * 100).round(2)\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing_counts,\n",
    "    'Missing %': missing_pct\n",
    "})\n",
    "print(missing_df[missing_df['Missing Count'] > 0])\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CATEGORICAL FEATURES IDENTIFIED\")\n",
    "print(\"=\" * 80)\n",
    "categorical_features = ['merchant_category', 'merchant_country', 'country', 'cc_num']\n",
    "print(categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "drfcrktx8gg",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify Preprocessing Pipeline\n",
    "# Check that all transformations were applied correctly\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"PREPROCESSING PIPELINE VERIFICATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Check data types\n",
    "print(\"Data types after preprocessing:\")\n",
    "print(X_train_processed.dtypes.value_counts())\n",
    "\n",
    "# Check for any remaining missing values\n",
    "print(f\"\\nMissing values: {X_train_processed.isnull().sum().sum()}\")\n",
    "\n",
    "# Display sample of transformed data\n",
    "print(\"\\nSample of transformed data:\")\n",
    "print(X_train_processed.head())\n",
    "\n",
    "# Show pipeline structure\n",
    "print(\"\\nPreprocessing Pipeline Structure:\")\n",
    "print(preprocessor)\n",
    "\n",
    "print(\"\\nAll preprocessing complete!\")\n",
    "print(f\"  ✓ Missing values imputed\")\n",
    "print(f\"  ✓ Categorical features encoded\")\n",
    "print(f\"  ✓ Pipeline can be saved and reused for inference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lwsvblh14am",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Predictions\n",
    "# Predict on the test set\n",
    "\n",
    "y_pred = xgb_classifier.predict(X_test_processed)\n",
    "y_pred_proba = xgb_classifier.predict_proba(X_test_processed)[:, 1]\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"PREDICTION SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Test set size:     {len(y_test):,}\")\n",
    "print(f\"Predicted frauds:  {y_pred.sum():,} ({y_pred.sum()/len(y_test)*100:.2f}%)\")\n",
    "print(f\"Actual frauds:     {y_test.sum():,} ({y_test.sum()/len(y_test)*100:.2f}%)\")\n",
    "print(f\"\\nPrediction probability range: [{y_pred_proba.min():.4f}, {y_pred_proba.max():.4f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ekjj2su1w15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance\n",
    "# Analyze which features are most important for fraud detection\n",
    "\n",
    "# Get feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X_train_processed.columns,\n",
    "    'importance': xgb_classifier.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# Display top 15 features\n",
    "print(\"=\" * 80)\n",
    "print(\"TOP 15 MOST IMPORTANT FEATURES\")\n",
    "print(\"=\" * 80)\n",
    "print(feature_importance.head(15).to_string(index=False))\n",
    "\n",
    "# Visualize feature importance\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "top_features = feature_importance.head(15)\n",
    "bars = ax.barh(top_features['feature'], top_features['importance'], color='steelblue')\n",
    "ax.set_xlabel('Importance Score', fontsize=12)\n",
    "ax.set_title('Top 15 Feature Importances - XGBoost Fraud Classifier', fontsize=14, fontweight='bold')\n",
    "ax.invert_yaxis()\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (bar, val) in enumerate(zip(bars, top_features['importance'])):\n",
    "    ax.text(val, bar.get_y() + bar.get_height()/2, f'{val:.4f}', \n",
    "            va='center', ha='left', fontsize=9, color='black')\n",
    "\n",
    "plt.tight_layout()\n",
    "feature_imp_fig = fig  # Store for saving later\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"Features with higher importance scores have more influence on fraud predictions.\")\n",
    "print(\"Geographic indicators, transaction patterns, and merchant history are key fraud signals.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2snng4pgiyw",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register Model in Hopsworks\n",
    "# Upload model to Hopsworks Model Registry for versioning and deployment\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"REGISTERING MODEL IN HOPSWORKS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Format metrics for model registry (must be strings)\n",
    "metrics_for_registry = {\n",
    "    'roc_auc': f\"{metrics_dict['roc_auc']:.4f}\",\n",
    "    'pr_auc': f\"{metrics_dict['pr_auc']:.4f}\",\n",
    "    'precision': f\"{metrics_dict['precision']:.4f}\",\n",
    "    'recall': f\"{metrics_dict['recall']:.4f}\",\n",
    "    'f1_score': f\"{metrics_dict['f1_score']:.4f}\",\n",
    "    'accuracy': f\"{metrics_dict['accuracy']:.4f}\",\n",
    "    'scale_pos_weight': f\"{scale_pos_weight:.2f}\",\n",
    "    'n_train_samples': str(len(y_train)),\n",
    "    'n_fraud_train': str(n_positive),\n",
    "    'imbalance_ratio': f\"{scale_pos_weight:.2f}:1\"\n",
    "}\n",
    "\n",
    "print(\"Model metadata:\")\n",
    "for key, value in metrics_for_registry.items():\n",
    "    print(f\"  {key:20s}: {value}\")\n",
    "\n",
    "# Create model in registry\n",
    "cc_fraud_model = mr.python.create_model(\n",
    "    name=\"cc_fraud_xgboost_model\",\n",
    "    metrics=metrics_for_registry,\n",
    "    feature_view=fv,\n",
    "    description=\"Credit Card Fraud Detection - XGBoost Binary Classifier with scale_pos_weight for class imbalance. \"\n",
    "                f\"Trained on {len(y_train):,} samples with {n_positive} fraud cases. \"\n",
    "                f\"Uses {len(X_train_processed.columns)} features after preprocessing.\"\n",
    ")\n",
    "\n",
    "# Upload model directory to registry\n",
    "cc_fraud_model.save(model_dir)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"MODEL REGISTRATION COMPLETE\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Model name: cc_fraud_xgboost_model\")\n",
    "print(f\"Version: {cc_fraud_model.version}\")\n",
    "print(f\"\\nExplore at: {cc_fraud_model._get_url()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qe25v3un9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model Artifacts\n",
    "# Save all necessary files for model inference and reproducibility\n",
    "\n",
    "import joblib\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SAVING MODEL ARTIFACTS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Save trained model\n",
    "model_path = model_dir + \"/cc_fraud_xgboost.pkl\"\n",
    "joblib.dump(xgb_classifier, model_path)\n",
    "print(f\"✓ Model saved to: {model_path}\")\n",
    "\n",
    "# Save complete preprocessing pipeline (imputation + encoding)\n",
    "preprocessor_path = model_dir + \"/preprocessor.pkl\"\n",
    "joblib.dump(preprocessor, preprocessor_path)\n",
    "print(f\"✓ Preprocessor pipeline saved to: {preprocessor_path}\")\n",
    "\n",
    "# Save confusion matrix image\n",
    "cm_fig.savefig(images_dir + \"/confusion_matrix.png\", dpi=100, bbox_inches='tight')\n",
    "print(f\"✓ Confusion matrix saved to: {images_dir}/confusion_matrix.png\")\n",
    "\n",
    "# Save feature importance image  \n",
    "feature_imp_fig.savefig(images_dir + \"/feature_importance.png\", dpi=100, bbox_inches='tight')\n",
    "print(f\"✓ Feature importance saved to: {images_dir}/feature_importance.png\")\n",
    "\n",
    "# Save feature names for inference\n",
    "feature_names_path = model_dir + \"/feature_names.pkl\"\n",
    "joblib.dump(list(X_train_processed.columns), feature_names_path)\n",
    "print(f\"✓ Feature names saved to: {feature_names_path}\")\n",
    "\n",
    "# Save features to drop list\n",
    "features_to_drop_path = model_dir + \"/features_to_drop.pkl\"\n",
    "joblib.dump(features_to_drop, features_to_drop_path)\n",
    "print(f\"✓ Features to drop list saved to: {features_to_drop_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ALL ARTIFACTS SAVED SUCCESSFULLY\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Total files: 6\")\n",
    "print(f\"  - Model: cc_fraud_xgboost.pkl\")\n",
    "print(f\"  - Preprocessor: preprocessor.pkl (imputation + encoding)\")\n",
    "print(f\"  - Feature schema: feature_names.pkl\")\n",
    "print(f\"  - Feature selection: features_to_drop.pkl\")\n",
    "print(f\"  - Visualizations: 2 PNG files\")\n",
    "print(\"\\nFor inference, load: preprocessor.pkl → transform data → model.pkl → predict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boyx3q3jcjs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Model Directory\n",
    "# Setup directory structure for saving model artifacts\n",
    "\n",
    "import os\n",
    "\n",
    "model_dir = \"cc_fraud_model\"\n",
    "images_dir = model_dir + \"/images\"\n",
    "\n",
    "# Create directories\n",
    "if not os.path.exists(model_dir):\n",
    "    os.mkdir(model_dir)\n",
    "    print(f\"Created directory: {model_dir}\")\n",
    "else:\n",
    "    print(f\"Directory already exists: {model_dir}\")\n",
    "\n",
    "if not os.path.exists(images_dir):\n",
    "    os.mkdir(images_dir)\n",
    "    print(f\"Created directory: {images_dir}\")\n",
    "else:\n",
    "    print(f\"Directory already exists: {images_dir}\")\n",
    "\n",
    "print(\"\\nModel artifacts will be saved to:\", model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1noca6yrgwj",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "# Visualize model performance showing true/false positives and negatives\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Visualize confusion matrix\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "df_cm = pd.DataFrame(cm, \n",
    "                     index=['True Non-Fraud', 'True Fraud'],\n",
    "                     columns=['Pred Non-Fraud', 'Pred Fraud'])\n",
    "\n",
    "sns.heatmap(df_cm, annot=True, fmt='d', cmap='Blues', ax=ax, cbar_kws={'label': 'Count'})\n",
    "ax.set_title('Confusion Matrix - Credit Card Fraud Detection', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('Actual', fontsize=12)\n",
    "ax.set_xlabel('Predicted', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "cm_fig = fig  # Store for saving later\n",
    "plt.show()\n",
    "\n",
    "# Print confusion matrix breakdown\n",
    "print(\"=\" * 80)\n",
    "print(\"CONFUSION MATRIX BREAKDOWN\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"True Negatives:  {cm[0,0]:5,} (correctly identified non-fraud)\")\n",
    "print(f\"False Positives: {cm[0,1]:5,} (non-fraud flagged as fraud)\")\n",
    "print(f\"False Negatives: {cm[1,0]:5,} (fraud missed - CRITICAL)\")\n",
    "print(f\"True Positives:  {cm[1,1]:5,} (correctly identified fraud)\")\n",
    "\n",
    "print(\"\\nKey Insights:\")\n",
    "if cm[1,0] > 0:\n",
    "    print(f\"  WARNING: {cm[1,0]} fraudulent transactions were missed!\")\n",
    "    print(f\"  This represents {cm[1,0]/(cm[1,0]+cm[1,1])*100:.1f}% of all actual frauds.\")\n",
    "if cm[0,1] > 0:\n",
    "    print(f\"  {cm[0,1]} legitimate transactions were flagged as fraud (false alarms).\")\n",
    "    print(f\"  This is {cm[0,1]/(cm[0,0]+cm[0,1])*100:.2f}% of all legitimate transactions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mravij0xv4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Metrics\n",
    "# Comprehensive evaluation with metrics appropriate for imbalanced classification\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, \n",
    "    roc_auc_score, precision_recall_curve, auc,\n",
    "    precision_score, recall_score, f1_score\n",
    ")\n",
    "\n",
    "# Classification report\n",
    "print(\"=\" * 80)\n",
    "print(\"CLASSIFICATION REPORT\")\n",
    "print(\"=\" * 80)\n",
    "report_dict = classification_report(y_test, y_pred, \n",
    "                                   target_names=['Non-Fraud', 'Fraud'],\n",
    "                                   output_dict=True)\n",
    "print(classification_report(y_test, y_pred, target_names=['Non-Fraud', 'Fraud']))\n",
    "\n",
    "# Calculate key metrics\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Precision-Recall AUC (more important than ROC-AUC for imbalanced data)\n",
    "precision_curve, recall_curve, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "pr_auc = auc(recall_curve, precision_curve)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"KEY METRICS SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"ROC-AUC Score:        {roc_auc:.4f}\")\n",
    "print(f\"PR-AUC Score:         {pr_auc:.4f}  <- More important for imbalanced data\")\n",
    "print(f\"Precision (Fraud):    {precision:.4f}\")\n",
    "print(f\"Recall (Fraud):       {recall:.4f}\")\n",
    "print(f\"F1-Score (Fraud):     {f1:.4f}\")\n",
    "\n",
    "# Store metrics for model registry\n",
    "metrics_dict = {\n",
    "    'roc_auc': roc_auc,\n",
    "    'pr_auc': pr_auc,\n",
    "    'precision': precision,\n",
    "    'recall': recall,\n",
    "    'f1_score': f1,\n",
    "    'accuracy': report_dict['accuracy']\n",
    "}\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(f\"  - Precision: {precision*100:.1f}% of predicted frauds are actually fraudulent\")\n",
    "print(f\"  - Recall: {recall*100:.1f}% of actual frauds were detected\")\n",
    "print(f\"  - PR-AUC: {pr_auc:.4f} measures precision-recall tradeoff (higher is better)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lpo6s4zj4zs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train XGBoost Model\n",
    "# Configure XGBoost for imbalanced binary classification\n",
    "\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure XGBoost with scale_pos_weight for class imbalance\n",
    "xgb_classifier = xgb.XGBClassifier(\n",
    "    scale_pos_weight=scale_pos_weight,  # Handle class imbalance\n",
    "    max_depth=6,                        # Control overfitting\n",
    "    learning_rate=0.1,                  # Standard learning rate\n",
    "    n_estimators=100,                   # Number of boosting rounds\n",
    "    eval_metric='aucpr',                # PR-AUC: best metric for imbalanced data\n",
    "    early_stopping_rounds=10,           # Stop if no improvement for 10 rounds\n",
    "    random_state=42,                    # Reproducibility\n",
    "    use_label_encoder=False,            # Avoid deprecation warning\n",
    "    enable_categorical=False            # We pre-encoded categoricals\n",
    ")\n",
    "\n",
    "# Create evaluation set for early stopping\n",
    "eval_set = [(X_train_processed, y_train), (X_test_processed, y_test)]\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"TRAINING XGBOOST MODEL\")\n",
    "print(\"=\" * 80)\n",
    "print(\"Model configuration:\")\n",
    "print(f\"  scale_pos_weight:      {scale_pos_weight:.2f}\")\n",
    "print(f\"  max_depth:             {xgb_classifier.max_depth}\")\n",
    "print(f\"  learning_rate:         {xgb_classifier.learning_rate}\")\n",
    "print(f\"  n_estimators:          {xgb_classifier.n_estimators}\")\n",
    "print(f\"  eval_metric:           {xgb_classifier.eval_metric}\")\n",
    "print(f\"  early_stopping_rounds: 10\")\n",
    "print(\"\\nTraining in progress...\")\n",
    "\n",
    "# Train the model\n",
    "xgb_classifier.fit(\n",
    "    X_train_processed, \n",
    "    y_train.values.ravel(),\n",
    "    eval_set=eval_set,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print(\"\\nTraining complete!\")\n",
    "print(f\"Best iteration: {xgb_classifier.best_iteration}\")\n",
    "print(f\"Best score (AUCPR): {xgb_classifier.best_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wncn6cybsz",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate scale_pos_weight\n",
    "# This is the key parameter for handling class imbalance in XGBoost\n",
    "\n",
    "n_negative = (y_train == False).sum()\n",
    "n_positive = (y_train == True).sum()\n",
    "scale_pos_weight = n_negative / n_positive\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"CLASS IMBALANCE ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Negative samples (non-fraud): {n_negative:,}\")\n",
    "print(f\"Positive samples (fraud):     {n_positive:,}\")\n",
    "print(f\"Imbalance ratio:              {scale_pos_weight:.2f}:1\")\n",
    "print(f\"\\nscale_pos_weight parameter:   {scale_pos_weight:.2f}\")\n",
    "print(\"\\nThis parameter tells XGBoost to give ~{:.0f}x more weight to fraud cases\".format(scale_pos_weight))\n",
    "print(\"during training to compensate for the severe class imbalance.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iagrphz9waq",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Preprocessing Pipeline\n",
    "# Use sklearn Pipeline for imputation and encoding (production-ready for inference)\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"CREATING PREPROCESSING PIPELINE\")\n",
    "print(\"=\" * 80)\n",
    "print(\"Missing values before preprocessing:\")\n",
    "print(X_train_processed.isnull().sum()[X_train_processed.isnull().sum() > 0])\n",
    "\n",
    "# Identify numeric and categorical columns\n",
    "categorical_features = ['merchant_category', 'merchant_country', 'country', 'prev_ip_transaction']\n",
    "numeric_features = [col for col in X_train_processed.columns if col not in categorical_features]\n",
    "\n",
    "print(f\"\\nNumeric features ({len(numeric_features)}): {numeric_features[:5]}...\")\n",
    "print(f\"Categorical features ({len(categorical_features)}): {categorical_features}\")\n",
    "\n",
    "# Create preprocessing pipeline with both imputation and encoding\n",
    "# Numeric pipeline: just impute missing values\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median'))\n",
    "])\n",
    "\n",
    "# Categorical pipeline: impute missing values then encode\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='UNKNOWN')),\n",
    "    ('encoder', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "])\n",
    "\n",
    "# Combine into a single ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ],\n",
    "    verbose_feature_names_out=False\n",
    ")\n",
    "\n",
    "# Fit and transform the data\n",
    "X_train_transformed = preprocessor.fit_transform(X_train_processed)\n",
    "X_test_transformed = preprocessor.transform(X_test_processed)\n",
    "\n",
    "# Get feature names after transformation\n",
    "feature_names_out = preprocessor.get_feature_names_out()\n",
    "\n",
    "# Convert back to DataFrame\n",
    "X_train_processed = pd.DataFrame(X_train_transformed, columns=feature_names_out, index=X_train_processed.index)\n",
    "X_test_processed = pd.DataFrame(X_test_transformed, columns=feature_names_out, index=X_test_processed.index)\n",
    "\n",
    "print(\"\\nAfter preprocessing pipeline:\")\n",
    "print(f\"  Missing values: {X_train_processed.isnull().sum().sum()}\")\n",
    "print(f\"  Train shape: {X_train_processed.shape}\")\n",
    "print(f\"  Test shape: {X_test_processed.shape}\")\n",
    "print(\"\\nPreprocessing pipeline (imputation + encoding) ready for inference!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kjrzxsww5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection\n",
    "# Drop features that should NOT be used for model training\n",
    "\n",
    "features_to_drop = [\n",
    "    'event_time',           # Timestamp - would cause data leakage\n",
    "    'prev_ts_transaction',  # Timestamp - not useful for tree models\n",
    "    'cc_num'                # High cardinality ID - would overfit\n",
    "]\n",
    "\n",
    "X_train_processed = X_train.drop(columns=features_to_drop)\n",
    "X_test_processed = X_test.drop(columns=features_to_drop)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"FEATURE SELECTION\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Original features: {X_train.shape[1]}\")\n",
    "print(f\"After dropping: {X_train_processed.shape[1]}\")\n",
    "print(f\"\\nDropped features: {features_to_drop}\")\n",
    "print(f\"\\nRemaining features ({len(X_train_processed.columns)}):\")\n",
    "for i, feat in enumerate(X_train_processed.columns, 1):\n",
    "    print(f\"  {i:2d}. {feat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1593cf33-3390-4015-aea2-86e9e3ff228b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
